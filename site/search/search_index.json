{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"The Applied Generative AI Engineering Handbook <p>             Zero theory-only fluff. A code-first curriculum taking you from tensor basics to deploying production-grade RAG agents.              Open Source. Interactive. Community-Driven. </p> <p>Select your path to start:</p> school                     Understanding AI                  code                     Engineering AI                  biotech                     Researching AI                  architecture                     Architecting AI                  business_center                     Business AI                  <p>MASTER THE MODERN AI STACK</p> \ud83d\udd25 PyTorch \ud83e\udd17 Hugging Face \u26a1 vLLM \ud83d\udcc8 Weights &amp; Biases \ud83d\ude80 FastAPI Everything you would expect <p>                 Interactive Jupyter notebooks with live code execution. Progressive learning paths with 50+ lessons and 200+ hands-on exercises.                  Production-ready projects including RAG systems, model deployment, and API development. Vibrant community of 5,000+ AI engineers                  with weekly events and real-time support.             </p>                  Stay ahead of the curve <p>                 Get the latest GenAI trends, tutorials, and model breakdowns delivered weekly.                 Join 10,000+ AI engineers staying updated.             </p>                      Subscribe                     arrow_forward <p> lock                 No spam ever. Unsubscribe anytime. Your privacy matters.             </p> Follow us on social media"},{"location":"community/","title":"Community","text":"Join Our Community <p>             Connect with AI enthusiasts, engineers, and researchers building the future together.         </p> 5,000+ Members 500+ GitHub Stars 100+ Contributors Discord <p>Real-time help &amp; study groups</p>                      Join Server                  GitHub <p>Open source &amp; contributions</p>                      View Repo                  X (Twitter) <p>Latest AI trends &amp; updates</p>                      Follow Us"},{"location":"contributing/","title":"Contributing","text":"Contributing <p>             Help make AI education accessible to everyone. All contributions welcome.         </p> Ways to Contribute \ud83d\udc1b Report Bugs <p>Open GitHub issues</p> \u2728 Suggest Features <p>Share your ideas</p> \ud83d\udcdd Improve Docs <p>Fix typos &amp; clarify</p> \ud83d\udcda Add Content <p>Create tutorials</p> \ud83c\udf0d Translate <p>Make it global</p> \ud83c\udfa8 Design &amp; UX <p>Improve visuals</p> Quick Start <p>             Fork the repo, make changes, and submit a PR. See the GitHub repository for detailed guidelines.         </p> <code># Clone and setup git clone https://github.com/YOUR-USERNAME/madeforai.git cd madeforai &amp;&amp; python -m venv venv source venv/bin/activate &amp;&amp; pip install -r requirements.txt  # Start development server mkdocs serve</code> Need Help? \ud83d\udcac Discord \ud83d\udcad Discussions \ud83d\udc1b Issues"},{"location":"hooks/notebook_enhancer/","title":"Notebook enhancer","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nMkDocs hook to enhance notebook rendering - Clean &amp; Minimal\n\"\"\"\n</pre> \"\"\" MkDocs hook to enhance notebook rendering - Clean &amp; Minimal \"\"\" In\u00a0[\u00a0]: Copied! <pre>import re\nfrom pathlib import Path\n</pre> import re from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>def on_page_content(html, page, config, files):\n    \"\"\"\n    Hook to modify the HTML content of notebook pages\n    \"\"\"\n    # Only process notebook pages\n    if not page.file.src_path.endswith('.ipynb'):\n        return html\n    \n    # Check if this is a notebook page\n    if 'jp-Notebook' not in html:\n        return html\n    \n    # Extract Title (H1)\n    title_match = re.search(r'&lt;h1.*?&gt;(.*?)&lt;/h1&gt;', html, re.DOTALL)\n    title = title_match.group(1) if title_match else \"Documentation\"\n    \n    # Remove \"Chapter X:\" prefix from title\n    title = re.sub(r'^Chapter\\s+\\d+:\\s*', '', title, flags=re.IGNORECASE)\n    \n    # Remove original H1\n    html = re.sub(r'&lt;h1.*?&gt;.*?&lt;/h1&gt;', '', html, count=1, flags=re.DOTALL)\n    \n    # Remove the Colab badge\n    html = re.sub(r'&lt;p&gt;\\s*&lt;a[^&gt;]*colab[^&gt;]*&gt;\\s*&lt;img[^&gt;]*colab-badge[^&gt;]*&gt;\\s*&lt;/a&gt;\\s*&lt;/p&gt;', '', html, flags=re.IGNORECASE)\n    \n    # Remove first HR\n    html = re.sub(r'&lt;hr&gt;\\s*', '', html, count=1)\n    \n    # Colab link\n    notebook_path = page.file.src_path\n    colab_url = f\"https://colab.research.google.com/github/madeforai/madeforai/blob/main/docs/{notebook_path}\"\n\n    # Minimal header\n    header_html = f\"\"\"\n    &lt;div class=\"nb-header\"&gt;\n        &lt;h1&gt;{title}&lt;/h1&gt;\n        &lt;a href=\"{colab_url}\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"nb-colab-btn\"&gt;\n            &lt;svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"currentColor\"&gt;\n                &lt;path d=\"M12 0C5.373 0 0 5.373 0 12s5.373 12 12 12 12-5.373 12-12S18.627 0 12 0zm0 2.4c5.302 0 9.6 4.298 9.6 9.6s-4.298 9.6-9.6 9.6S2.4 17.302 2.4 12 6.698 2.4 12 2.4z\"/&gt;\n                &lt;path d=\"M8.4 7.2h7.2v1.2H8.4zm0 2.4h7.2v1.2H8.4zm0 2.4h7.2v1.2H8.4zm0 2.4h4.8v1.2H8.4z\"/&gt;\n            &lt;/svg&gt;\n            Open in Colab\n        &lt;/a&gt;\n    &lt;/div&gt;\n    \"\"\"\n\n    return header_html + html\n</pre> def on_page_content(html, page, config, files):     \"\"\"     Hook to modify the HTML content of notebook pages     \"\"\"     # Only process notebook pages     if not page.file.src_path.endswith('.ipynb'):         return html          # Check if this is a notebook page     if 'jp-Notebook' not in html:         return html          # Extract Title (H1)     title_match = re.search(r'(.*?)', html, re.DOTALL)     title = title_match.group(1) if title_match else \"Documentation\"          # Remove \"Chapter X:\" prefix from title     title = re.sub(r'^Chapter\\s+\\d+:\\s*', '', title, flags=re.IGNORECASE)          # Remove original H1     html = re.sub(r'.*?', '', html, count=1, flags=re.DOTALL)          # Remove the Colab badge     html = re.sub(r'<p>\\s*]*colab[^&gt;]*&gt;\\s*]*colab-badge[^&gt;]*&gt;\\s*\\s*</p>', '', html, flags=re.IGNORECASE)          # Remove first HR     html = re.sub(r'\\s*', '', html, count=1)          # Colab link     notebook_path = page.file.src_path     colab_url = f\"https://colab.research.google.com/github/madeforai/madeforai/blob/main/docs/{notebook_path}\"      # Minimal header     header_html = f\"\"\"      {title}              Open in Colab               \"\"\"      return header_html + html In\u00a0[\u00a0]: Copied! <pre>def on_post_page(output, page, config):\n    \"\"\"\n    Minimal post-processing\n    \"\"\"\n    if not page.file.src_path.endswith('.ipynb'):\n        return output\n    \n    return output\n</pre> def on_post_page(output, page, config):     \"\"\"     Minimal post-processing     \"\"\"     if not page.file.src_path.endswith('.ipynb'):         return output          return output"},{"location":"hooks/path_generator/","title":"Path generator","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nPath Generator Hook for MkDocs\nAutomatically generates beautiful learning path pages with module and chapter listings\n\"\"\"\n</pre> \"\"\" Path Generator Hook for MkDocs Automatically generates beautiful learning path pages with module and chapter listings \"\"\" In\u00a0[\u00a0]: Copied! <pre>import os\nimport re\nfrom pathlib import Path\nimport logging\n</pre> import os import re from pathlib import Path import logging In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger('mkdocs.hooks.path_generator')\n</pre> logger = logging.getLogger('mkdocs.hooks.path_generator') In\u00a0[\u00a0]: Copied! <pre># Path configurations with colors and icons\nPATH_CONFIGS = {\n    'understanding-ai': {\n        'title': 'Understanding AI',\n        'subtitle': 'Build a solid foundation in AI fundamentals',\n        'description': 'Master the core concepts of artificial intelligence, machine learning, and deep learning. Build your first models and understand how modern AI systems work through hands-on interactive lessons.',\n        'icon': 'school',\n        'color': '#3b82f6',\n        'color_secondary': '#2563eb',\n        'prerequisites': [\n            'Basic Python programming',\n            'High school mathematics',\n            'Curiosity about AI'\n        ],\n        'outcomes': [\n            'Understand AI, ML, and Deep Learning',\n            'Build neural networks from scratch',\n            'Work with modern LLMs',\n            'Master prompt engineering basics'\n        ]\n    },\n    'engineering-ai': {\n        'title': 'Engineering AI',\n        'subtitle': 'Build production-ready LLM applications',\n        'description': 'Dive deep into transformer architecture, fine-tuning techniques, and deployment strategies. Learn to build scalable AI systems that work in production environments.',\n        'icon': 'code',\n        'color': '#8b5cf6',\n        'color_secondary': '#7c3aed',\n        'prerequisites': [\n            'Python programming experience',\n            'Basic ML concepts',\n            'Deep learning frameworks'\n        ],\n        'outcomes': [\n            'Master Transformer architecture',\n            'Fine-tune models with LoRA/QLoRA',\n            'Build RAG systems',\n            'Deploy LLMs to production'\n        ]\n    },\n    'researching-ai': {\n        'title': 'Researching AI',\n        'subtitle': 'Push the boundaries of AI innovation',\n        'description': 'Explore cutting-edge research, learn to read and implement papers, and contribute to the field. Develop the skills to design novel architectures and conduct rigorous experiments.',\n        'icon': 'biotech',\n        'color': '#ec4899',\n        'color_secondary': '#db2777',\n        'prerequisites': [\n            'Strong mathematical background',\n            'Deep learning fundamentals',\n            'Research experience helpful'\n        ],\n        'outcomes': [\n            'Read and implement papers',\n            'Design novel architectures',\n            'Conduct rigorous experiments',\n            'Contribute to open-source research'\n        ]\n    },\n    'architecting-ai': {\n        'title': 'Architecting AI',\n        'subtitle': 'Design scalable AI systems',\n        'description': 'Learn system design patterns, infrastructure choices, and best practices for building reliable, scalable AI systems. Master the art of architecting production-grade AI solutions.',\n        'icon': 'architecture',\n        'color': '#f59e0b',\n        'color_secondary': '#d97706',\n        'prerequisites': [\n            'System design experience',\n            'Cloud infrastructure knowledge',\n            'AI/ML basics'\n        ],\n        'outcomes': [\n            'Design scalable architectures',\n            'Choose optimal infrastructure',\n            'Implement monitoring systems',\n            'Optimize costs and performance'\n        ]\n    },\n    'business-ai': {\n        'title': 'Business AI',\n        'subtitle': 'Lead AI strategy and transformation',\n        'description': 'Understand AI strategy without diving into technical details. Learn to identify use cases, evaluate vendors, build teams, and navigate the business side of AI implementation.',\n        'icon': 'business_center',\n        'color': '#10b981',\n        'color_secondary': '#059669',\n        'prerequisites': [\n            'No technical background required',\n            'Business experience helpful',\n            'Interest in AI strategy'\n        ],\n        'outcomes': [\n            'Understand AI/LLM landscape',\n            'Identify high-value use cases',\n            'Make build vs. buy decisions',\n            'Build and manage AI teams'\n        ]\n    }\n}\n</pre> # Path configurations with colors and icons PATH_CONFIGS = {     'understanding-ai': {         'title': 'Understanding AI',         'subtitle': 'Build a solid foundation in AI fundamentals',         'description': 'Master the core concepts of artificial intelligence, machine learning, and deep learning. Build your first models and understand how modern AI systems work through hands-on interactive lessons.',         'icon': 'school',         'color': '#3b82f6',         'color_secondary': '#2563eb',         'prerequisites': [             'Basic Python programming',             'High school mathematics',             'Curiosity about AI'         ],         'outcomes': [             'Understand AI, ML, and Deep Learning',             'Build neural networks from scratch',             'Work with modern LLMs',             'Master prompt engineering basics'         ]     },     'engineering-ai': {         'title': 'Engineering AI',         'subtitle': 'Build production-ready LLM applications',         'description': 'Dive deep into transformer architecture, fine-tuning techniques, and deployment strategies. Learn to build scalable AI systems that work in production environments.',         'icon': 'code',         'color': '#8b5cf6',         'color_secondary': '#7c3aed',         'prerequisites': [             'Python programming experience',             'Basic ML concepts',             'Deep learning frameworks'         ],         'outcomes': [             'Master Transformer architecture',             'Fine-tune models with LoRA/QLoRA',             'Build RAG systems',             'Deploy LLMs to production'         ]     },     'researching-ai': {         'title': 'Researching AI',         'subtitle': 'Push the boundaries of AI innovation',         'description': 'Explore cutting-edge research, learn to read and implement papers, and contribute to the field. Develop the skills to design novel architectures and conduct rigorous experiments.',         'icon': 'biotech',         'color': '#ec4899',         'color_secondary': '#db2777',         'prerequisites': [             'Strong mathematical background',             'Deep learning fundamentals',             'Research experience helpful'         ],         'outcomes': [             'Read and implement papers',             'Design novel architectures',             'Conduct rigorous experiments',             'Contribute to open-source research'         ]     },     'architecting-ai': {         'title': 'Architecting AI',         'subtitle': 'Design scalable AI systems',         'description': 'Learn system design patterns, infrastructure choices, and best practices for building reliable, scalable AI systems. Master the art of architecting production-grade AI solutions.',         'icon': 'architecture',         'color': '#f59e0b',         'color_secondary': '#d97706',         'prerequisites': [             'System design experience',             'Cloud infrastructure knowledge',             'AI/ML basics'         ],         'outcomes': [             'Design scalable architectures',             'Choose optimal infrastructure',             'Implement monitoring systems',             'Optimize costs and performance'         ]     },     'business-ai': {         'title': 'Business AI',         'subtitle': 'Lead AI strategy and transformation',         'description': 'Understand AI strategy without diving into technical details. Learn to identify use cases, evaluate vendors, build teams, and navigate the business side of AI implementation.',         'icon': 'business_center',         'color': '#10b981',         'color_secondary': '#059669',         'prerequisites': [             'No technical background required',             'Business experience helpful',             'Interest in AI strategy'         ],         'outcomes': [             'Understand AI/LLM landscape',             'Identify high-value use cases',             'Make build vs. buy decisions',             'Build and manage AI teams'         ]     } } In\u00a0[\u00a0]: Copied! <pre>def extract_title_from_notebook(notebook_path):\n    \"\"\"Extract title from Jupyter notebook\"\"\"\n    try:\n        import json\n        with open(notebook_path, 'r', encoding='utf-8') as f:\n            nb = json.load(f)\n            # Look for first markdown cell with heading\n            for cell in nb.get('cells', []):\n                if cell.get('cell_type') == 'markdown':\n                    source = ''.join(cell.get('source', []))\n                    # Find first heading\n                    match = re.search(r'^#\\s+(.+)$', source, re.MULTILINE)\n                    if match:\n                        title = match.group(1).strip()\n                        # Clean up title - remove \"Chapter X:\" prefix\n                        title = re.sub(r'^Chapter\\s+\\d+:\\s*', '', title, flags=re.IGNORECASE)\n                        return title\n    except Exception as e:\n        logger.warning(f\"Could not extract title from {notebook_path}: {e}\")\n    return None\n</pre> def extract_title_from_notebook(notebook_path):     \"\"\"Extract title from Jupyter notebook\"\"\"     try:         import json         with open(notebook_path, 'r', encoding='utf-8') as f:             nb = json.load(f)             # Look for first markdown cell with heading             for cell in nb.get('cells', []):                 if cell.get('cell_type') == 'markdown':                     source = ''.join(cell.get('source', []))                     # Find first heading                     match = re.search(r'^#\\s+(.+)$', source, re.MULTILINE)                     if match:                         title = match.group(1).strip()                         # Clean up title - remove \"Chapter X:\" prefix                         title = re.sub(r'^Chapter\\s+\\d+:\\s*', '', title, flags=re.IGNORECASE)                         return title     except Exception as e:         logger.warning(f\"Could not extract title from {notebook_path}: {e}\")     return None In\u00a0[\u00a0]: Copied! <pre>def parse_chapter_number(filename):\n    \"\"\"Parse chapter number from filename like '1.1-title.ipynb' or '2.3-title.ipynb'\"\"\"\n    match = re.match(r'(\\d+)\\.(\\d+)', filename)\n    if match:\n        module_num = int(match.group(1))\n        chapter_num = int(match.group(2))\n        return module_num, chapter_num, f\"{module_num}.{chapter_num}\"\n    return None, None, None\n</pre> def parse_chapter_number(filename):     \"\"\"Parse chapter number from filename like '1.1-title.ipynb' or '2.3-title.ipynb'\"\"\"     match = re.match(r'(\\d+)\\.(\\d+)', filename)     if match:         module_num = int(match.group(1))         chapter_num = int(match.group(2))         return module_num, chapter_num, f\"{module_num}.{chapter_num}\"     return None, None, None In\u00a0[\u00a0]: Copied! <pre>def scan_path_content(docs_path, path_slug):\n    \"\"\"Scan a learning path directory for modules and chapters\"\"\"\n    path_dir = Path(docs_path) / 'paths' / path_slug\n    \n    if not path_dir.exists():\n        return {}\n    \n    modules = {}\n    \n    # Scan for notebooks directly in path directory (flat structure)\n    for item in path_dir.iterdir():\n        if item.is_file() and item.suffix == '.ipynb' and not item.name.startswith('.'):\n            module_num, chapter_num, chapter_id = parse_chapter_number(item.name)\n            \n            if module_num is not None:\n                # Extract title\n                title = extract_title_from_notebook(item)\n                if not title:\n                    # Fallback: use filename\n                    title = item.stem.split('-', 1)[1].replace('-', ' ').title() if '-' in item.stem else item.stem\n                \n                # Add to modules\n                if module_num not in modules:\n                    modules[module_num] = {\n                        'title': f'{module_num}',\n                        'chapters': []\n                    }\n                \n                modules[module_num]['chapters'].append({\n                    'id': chapter_id,\n                    'number': chapter_num,\n                    'title': title,\n                    'file': item.stem  # Remove .ipynb extension\n                })\n    \n    # Scan for module directories (nested structure like module-1-foundations)\n    for item in path_dir.iterdir():\n        if item.is_dir() and not item.name.startswith('.'):\n            # Try to extract module number from directory name\n            dir_match = re.match(r'module-(\\d+)', item.name)\n            if dir_match:\n                module_num = int(dir_match.group(1))\n                \n                # Extract module title from directory name - just number and name\n                if len(item.name.split('-')) &gt; 2:\n                    module_title_part = item.name.split('-', 2)[2]\n                    module_title = f\"{module_num} - {module_title_part.replace('-', ' ').title()}\"\n                else:\n                    module_title = f'{module_num}'\n                \n                if module_num not in modules:\n                    modules[module_num] = {\n                        'title': module_title,\n                        'chapters': []\n                    }\n                else:\n                    modules[module_num]['title'] = module_title\n                \n                # Scan for chapters in module directory\n                for chapter_file in item.iterdir():\n                    if chapter_file.is_file() and chapter_file.suffix == '.ipynb' and not chapter_file.name.startswith('.'):\n                        mod_num, chap_num, chapter_id = parse_chapter_number(chapter_file.name)\n                        \n                        if mod_num == module_num and chap_num is not None:\n                            # Extract title\n                            title = extract_title_from_notebook(chapter_file)\n                            if not title:\n                                title = chapter_file.stem.split('-', 1)[1].replace('-', ' ').title() if '-' in chapter_file.stem else chapter_file.stem\n                            \n                            # Relative path from path directory - remove .ipynb extension\n                            rel_path = f\"{item.name}/{chapter_file.stem}\"\n                            \n                            modules[module_num]['chapters'].append({\n                                'id': chapter_id,\n                                'number': chap_num,\n                                'title': title,\n                                'file': rel_path\n                            })\n    \n    # Sort chapters within each module\n    for module in modules.values():\n        module['chapters'].sort(key=lambda x: x['number'])\n    \n    return modules\n</pre> def scan_path_content(docs_path, path_slug):     \"\"\"Scan a learning path directory for modules and chapters\"\"\"     path_dir = Path(docs_path) / 'paths' / path_slug          if not path_dir.exists():         return {}          modules = {}          # Scan for notebooks directly in path directory (flat structure)     for item in path_dir.iterdir():         if item.is_file() and item.suffix == '.ipynb' and not item.name.startswith('.'):             module_num, chapter_num, chapter_id = parse_chapter_number(item.name)                          if module_num is not None:                 # Extract title                 title = extract_title_from_notebook(item)                 if not title:                     # Fallback: use filename                     title = item.stem.split('-', 1)[1].replace('-', ' ').title() if '-' in item.stem else item.stem                                  # Add to modules                 if module_num not in modules:                     modules[module_num] = {                         'title': f'{module_num}',                         'chapters': []                     }                                  modules[module_num]['chapters'].append({                     'id': chapter_id,                     'number': chapter_num,                     'title': title,                     'file': item.stem  # Remove .ipynb extension                 })          # Scan for module directories (nested structure like module-1-foundations)     for item in path_dir.iterdir():         if item.is_dir() and not item.name.startswith('.'):             # Try to extract module number from directory name             dir_match = re.match(r'module-(\\d+)', item.name)             if dir_match:                 module_num = int(dir_match.group(1))                                  # Extract module title from directory name - just number and name                 if len(item.name.split('-')) &gt; 2:                     module_title_part = item.name.split('-', 2)[2]                     module_title = f\"{module_num} - {module_title_part.replace('-', ' ').title()}\"                 else:                     module_title = f'{module_num}'                                  if module_num not in modules:                     modules[module_num] = {                         'title': module_title,                         'chapters': []                     }                 else:                     modules[module_num]['title'] = module_title                                  # Scan for chapters in module directory                 for chapter_file in item.iterdir():                     if chapter_file.is_file() and chapter_file.suffix == '.ipynb' and not chapter_file.name.startswith('.'):                         mod_num, chap_num, chapter_id = parse_chapter_number(chapter_file.name)                                                  if mod_num == module_num and chap_num is not None:                             # Extract title                             title = extract_title_from_notebook(chapter_file)                             if not title:                                 title = chapter_file.stem.split('-', 1)[1].replace('-', ' ').title() if '-' in chapter_file.stem else chapter_file.stem                                                          # Relative path from path directory - remove .ipynb extension                             rel_path = f\"{item.name}/{chapter_file.stem}\"                                                          modules[module_num]['chapters'].append({                                 'id': chapter_id,                                 'number': chap_num,                                 'title': title,                                 'file': rel_path                             })          # Sort chapters within each module     for module in modules.values():         module['chapters'].sort(key=lambda x: x['number'])          return modules In\u00a0[\u00a0]: Copied! <pre>def generate_module_html(module_num, module_data, config, has_content=True):\n    \"\"\"Generate HTML for a single module card\"\"\"\n    color = config['color']\n    chapters_html = ''\n    \n    if has_content and module_data['chapters']:\n        chapters_html = '&lt;div class=\"chapter-list\"&gt;'\n        for chapter in module_data['chapters']:\n            chapters_html += f'''\n            &lt;a href=\"{chapter['file']}\" class=\"chapter-link\"&gt;\n                &lt;span class=\"material-symbols-outlined\"&gt;play_circle&lt;/span&gt;\n                &lt;span&gt;{chapter['title']}&lt;/span&gt;\n            &lt;/a&gt;'''\n        chapters_html += '&lt;/div&gt;'\n    \n    card_class = 'module-card' if has_content else 'module-card coming-soon'\n    \n    return f'''\n    &lt;div class=\"{card_class}\"&gt;\n        &lt;div class=\"module-header\"&gt;\n            &lt;div class=\"module-number\"&gt;{module_num}&lt;/div&gt;\n            &lt;h3 class=\"module-title\"&gt;{module_data['title']}&lt;/h3&gt;\n            {'' if has_content else '&lt;span class=\"coming-soon-badge\"&gt;Coming Soon&lt;/span&gt;'}\n        &lt;/div&gt;\n        {chapters_html}\n    &lt;/div&gt;'''\n</pre> def generate_module_html(module_num, module_data, config, has_content=True):     \"\"\"Generate HTML for a single module card\"\"\"     color = config['color']     chapters_html = ''          if has_content and module_data['chapters']:         chapters_html = ''         for chapter in module_data['chapters']:             chapters_html += f'''              play_circle {chapter['title']} '''         chapters_html += ''          card_class = 'module-card' if has_content else 'module-card coming-soon'          return f'''      {module_num} {module_data['title']}             {'' if has_content else 'Coming Soon'}                  {chapters_html}     ''' In\u00a0[\u00a0]: Copied! <pre>def generate_path_page(path_slug, config, modules):\n    \"\"\"Generate complete path page HTML\"\"\"\n    has_modules = len(modules) &gt; 0\n    \n    # Generate modules HTML\n    modules_html = ''\n    if has_modules:\n        for module_num in sorted(modules.keys()):\n            modules_html += generate_module_html(module_num, modules[module_num], config, True)\n    else:\n        # Show coming soon message\n        modules_html = '''\n        &lt;div class=\"coming-soon-message\"&gt;\n            &lt;span class=\"material-symbols-outlined\"&gt;schedule&lt;/span&gt;\n            &lt;h3&gt;Coming Soon&lt;/h3&gt;\n            &lt;p&gt;This learning path is under development. Check back soon for updates!&lt;/p&gt;\n        &lt;/div&gt;'''\n    \n    return f'''---\ntitle: {config['title']}\ndescription: {config['subtitle']}\n---\n\n&lt;style&gt;\n/* Vertical Stacked Path Page Layout */\n.md-content__inner {{\n    max-width: 900px;\n    margin: 0 auto;\n}}\n\n.path-header {{\n    background: #ffffff;\n    border: 1px solid #e2e8f0;\n    border-radius: 1rem;\n    padding: 2rem;\n    margin: 2rem 0;\n    text-align: center;\n}}\n\n.path-icon {{\n    display: inline-flex;\n    align-items: center;\n    justify-content: center;\n    width: 56px;\n    height: 56px;\n    background: linear-gradient(135deg, {config['color']} 0%, {config['color_secondary']} 100%);\n    border-radius: 0.75rem;\n    margin-bottom: 1rem;\n}}\n\n.path-icon .material-symbols-outlined {{\n    font-size: 1.75rem;\n    color: #ffffff;\n    font-weight: 400;\n}}\n\n.path-title {{\n    font-family: 'Plus Jakarta Sans', sans-serif;\n    font-size: 2rem;\n    font-weight: 800;\n    color: #0f172a;\n    margin: 0 0 0.5rem 0;\n    letter-spacing: -0.025em;\n}}\n\n.path-subtitle {{\n    font-size: 1rem;\n    color: #64748b;\n    margin: 0 0 1rem 0;\n    font-weight: 600;\n}}\n\n.path-description {{\n    font-size: 0.9375rem;\n    color: #475569;\n    line-height: 1.6;\n    margin: 0;\n    max-width: 700px;\n    margin-left: auto;\n    margin-right: auto;\n}}\n\n.modules-section {{\n    margin: 2rem 0;\n}}\n\n.modules-header {{\n    margin-bottom: 1.5rem;\n}}\n\n.modules-title {{\n    font-family: 'Plus Jakarta Sans', sans-serif;\n    font-size: 1.5rem;\n    font-weight: 700;\n    color: #0f172a;\n    margin: 0;\n    letter-spacing: -0.025em;\n}}\n\n.module-card {{\n    background: #ffffff;\n    border: 1px solid #e2e8f0;\n    border-radius: 0.75rem;\n    padding: 1.5rem;\n    margin-bottom: 1.25rem;\n    transition: all 0.2s ease;\n}}\n\n.module-card:hover {{\n    border-color: {config['color']};\n    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n    transform: translateY(-2px);\n}}\n\n.module-header {{\n    display: flex;\n    align-items: center;\n    gap: 1rem;\n    margin-bottom: 1rem;\n}}\n\n.module-number {{\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    width: 36px;\n    height: 36px;\n    background: linear-gradient(135deg, {config['color']} 0%, {config['color_secondary']} 100%);\n    color: #ffffff;\n    border-radius: 0.5rem;\n    font-weight: 700;\n    font-size: 1rem;\n    flex-shrink: 0;\n}}\n\n.module-title {{\n    font-family: 'Plus Jakarta Sans', sans-serif;\n    font-size: 1.125rem;\n    font-weight: 700;\n    color: #0f172a;\n    margin: 0;\n}}\n\n.chapter-list {{\n    display: flex;\n    flex-direction: column;\n    gap: 0.625rem;\n}}\n\n.chapter-link {{\n    display: flex;\n    align-items: center;\n    gap: 0.75rem;\n    padding: 0.75rem 1rem;\n    background: #f8fafc;\n    border: 1px solid #e2e8f0;\n    border-radius: 0.5rem;\n    text-decoration: none;\n    color: #475569;\n    font-weight: 500;\n    font-size: 0.9375rem;\n    transition: all 0.2s ease;\n}}\n\n.chapter-link:hover {{\n    background: {config['color']}10;\n    border-color: {config['color']};\n    color: #0f172a;\n    transform: translateX(4px);\n}}\n\n.chapter-link .material-symbols-outlined {{\n    font-size: 1.125rem;\n    color: {config['color']};\n    flex-shrink: 0;\n}}\n\n.module-card.coming-soon {{\n    background: #f9fafb;\n    border-style: dashed;\n    border-color: #d1d5db;\n    opacity: 0.7;\n}}\n\n.module-card.coming-soon .module-number {{\n    background: #9ca3af;\n}}\n\n.module-card.coming-soon .module-title {{\n    color: #6b7280;\n}}\n\n.coming-soon-badge {{\n    display: inline-block;\n    padding: 0.25rem 0.75rem;\n    background: #f1f5f9;\n    color: #64748b;\n    border-radius: 9999px;\n    font-size: 0.75rem;\n    font-weight: 600;\n    text-transform: uppercase;\n    letter-spacing: 0.05em;\n}}\n\n.coming-soon-message {{\n    text-align: center;\n    padding: 3rem 2rem;\n    background: #f9fafb;\n    border: 2px dashed #e2e8f0;\n    border-radius: 1rem;\n}}\n\n.coming-soon-message .material-symbols-outlined {{\n    font-size: 3rem;\n    color: #9ca3af;\n    margin-bottom: 1rem;\n}}\n\n.coming-soon-message h3 {{\n    font-family: 'Plus Jakarta Sans', sans-serif;\n    font-size: 1.25rem;\n    font-weight: 700;\n    color: #6b7280;\n    margin: 0 0 0.5rem 0;\n}}\n\n.coming-soon-message p {{\n    font-size: 0.9375rem;\n    color: #9ca3af;\n    margin: 0;\n}}\n\n/* Hide feedback widget */\n.md-feedback {{\n    display: none !important;\n}}\n&lt;/style&gt;\n\n&lt;div class=\"path-header\"&gt;\n    &lt;div class=\"path-icon\"&gt;\n        &lt;span class=\"material-symbols-outlined\"&gt;{config['icon']}&lt;/span&gt;\n    &lt;/div&gt;\n    &lt;h1 class=\"path-title\"&gt;{config['title']}&lt;/h1&gt;\n    &lt;p class=\"path-subtitle\"&gt;{config['subtitle']}&lt;/p&gt;\n    &lt;p class=\"path-description\"&gt;{config['description']}&lt;/p&gt;\n&lt;/div&gt;\n\n&lt;div class=\"modules-section\"&gt;\n    &lt;div class=\"modules-header\"&gt;\n        &lt;h2 class=\"modules-title\"&gt;Learning Modules&lt;/h2&gt;\n    &lt;/div&gt;\n    \n    {modules_html}\n&lt;/div&gt;\n'''\n</pre> def generate_path_page(path_slug, config, modules):     \"\"\"Generate complete path page HTML\"\"\"     has_modules = len(modules) &gt; 0          # Generate modules HTML     modules_html = ''     if has_modules:         for module_num in sorted(modules.keys()):             modules_html += generate_module_html(module_num, modules[module_num], config, True)     else:         # Show coming soon message         modules_html = '''          schedule Coming Soon <p>This learning path is under development. Check back soon for updates!</p> '''          return f'''--- title: {config['title']} description: {config['subtitle']} ---   {config['icon']} {config['title']} <p>{config['subtitle']}</p> <p>{config['description']}</p> Learning Modules           {modules_html}  ''' In\u00a0[\u00a0]: Copied! <pre>def on_pre_build(config):\n    \"\"\"Hook that runs before the build starts\"\"\"\n    docs_dir = config['docs_dir']\n    \n    logger.info(\"Generating learning path pages...\")\n    \n    for path_slug, path_config in PATH_CONFIGS.items():\n        # Scan for modules and chapters\n        modules = scan_path_content(docs_dir, path_slug)\n        \n        # Generate page content\n        page_content = generate_path_page(path_slug, path_config, modules)\n        \n        # Write to index.md\n        index_path = Path(docs_dir) / 'paths' / path_slug / 'index.md'\n        if index_path.parent.exists():\n            with open(index_path, 'w', encoding='utf-8') as f:\n                f.write(page_content)\n            logger.info(f\"Generated {path_slug}/index.md with {len(modules)} modules\")\n</pre> def on_pre_build(config):     \"\"\"Hook that runs before the build starts\"\"\"     docs_dir = config['docs_dir']          logger.info(\"Generating learning path pages...\")          for path_slug, path_config in PATH_CONFIGS.items():         # Scan for modules and chapters         modules = scan_path_content(docs_dir, path_slug)                  # Generate page content         page_content = generate_path_page(path_slug, path_config, modules)                  # Write to index.md         index_path = Path(docs_dir) / 'paths' / path_slug / 'index.md'         if index_path.parent.exists():             with open(index_path, 'w', encoding='utf-8') as f:                 f.write(page_content)             logger.info(f\"Generated {path_slug}/index.md with {len(modules)} modules\")"},{"location":"paths/architecting-ai/","title":"Architecting AI","text":"architecture Architecting AI <p>Design scalable AI systems</p> <p>Learn system design patterns, infrastructure choices, and best practices for building reliable, scalable AI systems. Master the art of architecting production-grade AI solutions.</p> Learning Modules schedule Coming Soon <p>This learning path is under development. Check back soon for updates!</p>"},{"location":"paths/business-ai/","title":"Business AI","text":"business_center Business AI <p>Lead AI strategy and transformation</p> <p>Understand AI strategy without diving into technical details. Learn to identify use cases, evaluate vendors, build teams, and navigate the business side of AI implementation.</p> Learning Modules schedule Coming Soon <p>This learning path is under development. Check back soon for updates!</p>"},{"location":"paths/engineering-ai/","title":"Engineering AI","text":"code Engineering AI <p>Build production-ready LLM applications</p> <p>Dive deep into transformer architecture, fine-tuning techniques, and deployment strategies. Learn to build scalable AI systems that work in production environments.</p> Learning Modules 1 1 play_circle 1.1 - Deep Dive: The Transformer Architecture"},{"location":"paths/engineering-ai/1.1-transformer-architecture/","title":"1.1 - Deep Dive: The Transformer Architecture","text":"1.1 - Deep Dive: The Transformer Architecture\u00b6              Open in Colab          <p>\ud83d\udcbb The Engineer Path | Module 1 of 7</p> <p>The Transformer architecture, introduced in the seminal paper \"Attention Is All You Need\", revolutionized natural language processing by dispensing with recurrence and convolutions entirely. Instead, it relies solely on attention mechanisms to draw global dependencies between input and output.</p> In\u00a0[\u00a0]: Copied! <pre># Install required packages (uncomment if running in Colab)\n# !pip install torch numpy matplotlib -q\n</pre> # Install required packages (uncomment if running in Colab) # !pip install torch numpy matplotlib -q In\u00a0[\u00a0]: Copied! <pre>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"Using device: {device}\")\nprint(\"\u2705 Setup complete!\")\n</pre> import torch import torch.nn as nn import torch.nn.functional as F import numpy as np import matplotlib.pyplot as plt import math  # Set device device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') print(f\"PyTorch version: {torch.__version__}\") print(f\"Using device: {device}\") print(\"\u2705 Setup complete!\") In\u00a0[\u00a0]: Copied! <pre>def scaled_dot_product_attention(Q, K, V, mask=None):\n    \"\"\"\n    Compute scaled dot-product attention.\n    \n    Args:\n        Q: Queries of shape (batch, seq_len, d_k)\n        K: Keys of shape (batch, seq_len, d_k)\n        V: Values of shape (batch, seq_len, d_v)\n        mask: Optional mask for future tokens\n        \n    Returns:\n        Output and attention weights\n    \"\"\"\n    d_k = Q.size(-1)\n    \n    # Compute attention scores: QK^T / sqrt(d_k)\n    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n    \n    # Apply mask if provided (for decoder)\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, float('-inf'))\n    \n    # Softmax to get attention weights\n    attention_weights = F.softmax(scores, dim=-1)\n    \n    # Multiply by values\n    output = torch.matmul(attention_weights, V)\n    \n    return output, attention_weights\n</pre> def scaled_dot_product_attention(Q, K, V, mask=None):     \"\"\"     Compute scaled dot-product attention.          Args:         Q: Queries of shape (batch, seq_len, d_k)         K: Keys of shape (batch, seq_len, d_k)         V: Values of shape (batch, seq_len, d_v)         mask: Optional mask for future tokens              Returns:         Output and attention weights     \"\"\"     d_k = Q.size(-1)          # Compute attention scores: QK^T / sqrt(d_k)     scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)          # Apply mask if provided (for decoder)     if mask is not None:         scores = scores.masked_fill(mask == 0, float('-inf'))          # Softmax to get attention weights     attention_weights = F.softmax(scores, dim=-1)          # Multiply by values     output = torch.matmul(attention_weights, V)          return output, attention_weights In\u00a0[\u00a0]: Copied! <pre># Example: Self-attention on a simple sequence\nbatch_size = 1\nseq_len = 4\nd_model = 8\n\n# Create sample input (random vectors for 4 tokens)\ntorch.manual_seed(42)\nx = torch.randn(batch_size, seq_len, d_model)\n\n# For self-attention, Q = K = V = input (or linear projections)\nQ = K = V = x\n\n# Compute attention\noutput, attn_weights = scaled_dot_product_attention(Q, K, V)\n\nprint(f\"Input shape: {x.shape}\")\nprint(f\"Output shape: {output.shape}\")\nprint(f\"\\nAttention weights (how much each token attends to others):\")\nprint(attn_weights.squeeze().numpy().round(3))\n</pre> # Example: Self-attention on a simple sequence batch_size = 1 seq_len = 4 d_model = 8  # Create sample input (random vectors for 4 tokens) torch.manual_seed(42) x = torch.randn(batch_size, seq_len, d_model)  # For self-attention, Q = K = V = input (or linear projections) Q = K = V = x  # Compute attention output, attn_weights = scaled_dot_product_attention(Q, K, V)  print(f\"Input shape: {x.shape}\") print(f\"Output shape: {output.shape}\") print(f\"\\nAttention weights (how much each token attends to others):\") print(attn_weights.squeeze().numpy().round(3)) In\u00a0[\u00a0]: Copied! <pre># Visualize attention weights\nplt.figure(figsize=(8, 6))\nplt.imshow(attn_weights.squeeze().numpy(), cmap='Blues', aspect='auto')\nplt.colorbar(label='Attention Weight')\nplt.xlabel('Key Position')\nplt.ylabel('Query Position')\nplt.title('Self-Attention Weights')\nplt.xticks(range(seq_len), [f'Token {i}' for i in range(seq_len)])\nplt.yticks(range(seq_len), [f'Token {i}' for i in range(seq_len)])\nplt.tight_layout()\nplt.show()\n</pre> # Visualize attention weights plt.figure(figsize=(8, 6)) plt.imshow(attn_weights.squeeze().numpy(), cmap='Blues', aspect='auto') plt.colorbar(label='Attention Weight') plt.xlabel('Key Position') plt.ylabel('Query Position') plt.title('Self-Attention Weights') plt.xticks(range(seq_len), [f'Token {i}' for i in range(seq_len)]) plt.yticks(range(seq_len), [f'Token {i}' for i in range(seq_len)]) plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>class MultiHeadAttention(nn.Module):\n    \"\"\"Multi-Head Attention mechanism.\"\"\"\n    \n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        \n        # Linear projections for Q, K, V\n        self.W_q = nn.Linear(d_model, d_model, bias=False)\n        self.W_k = nn.Linear(d_model, d_model, bias=False)\n        self.W_v = nn.Linear(d_model, d_model, bias=False)\n        \n        # Output projection\n        self.W_o = nn.Linear(d_model, d_model, bias=False)\n        \n    def forward(self, Q, K, V, mask=None):\n        batch_size = Q.size(0)\n        \n        # Linear projections\n        Q = self.W_q(Q)\n        K = self.W_k(K)\n        V = self.W_v(V)\n        \n        # Reshape to (batch, num_heads, seq_len, d_k)\n        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        \n        # Compute attention\n        attn_output, attn_weights = scaled_dot_product_attention(Q, K, V, mask)\n        \n        # Concatenate heads\n        attn_output = attn_output.transpose(1, 2).contiguous().view(\n            batch_size, -1, self.d_model\n        )\n        \n        # Final linear projection\n        output = self.W_o(attn_output)\n        \n        return output, attn_weights\n</pre> class MultiHeadAttention(nn.Module):     \"\"\"Multi-Head Attention mechanism.\"\"\"          def __init__(self, d_model, num_heads):         super().__init__()         assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"                  self.d_model = d_model         self.num_heads = num_heads         self.d_k = d_model // num_heads                  # Linear projections for Q, K, V         self.W_q = nn.Linear(d_model, d_model, bias=False)         self.W_k = nn.Linear(d_model, d_model, bias=False)         self.W_v = nn.Linear(d_model, d_model, bias=False)                  # Output projection         self.W_o = nn.Linear(d_model, d_model, bias=False)              def forward(self, Q, K, V, mask=None):         batch_size = Q.size(0)                  # Linear projections         Q = self.W_q(Q)         K = self.W_k(K)         V = self.W_v(V)                  # Reshape to (batch, num_heads, seq_len, d_k)         Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)         K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)         V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)                  # Compute attention         attn_output, attn_weights = scaled_dot_product_attention(Q, K, V, mask)                  # Concatenate heads         attn_output = attn_output.transpose(1, 2).contiguous().view(             batch_size, -1, self.d_model         )                  # Final linear projection         output = self.W_o(attn_output)                  return output, attn_weights In\u00a0[\u00a0]: Copied! <pre># Test Multi-Head Attention\nd_model = 512\nnum_heads = 8\nseq_len = 10\nbatch_size = 2\n\nmha = MultiHeadAttention(d_model, num_heads)\nx = torch.randn(batch_size, seq_len, d_model)\n\noutput, attn_weights = mha(x, x, x)  # Self-attention\n\nprint(f\"Input shape: {x.shape}\")\nprint(f\"Output shape: {output.shape}\")\nprint(f\"Attention weights shape: {attn_weights.shape}\")\nprint(f\"\\n\u2705 Multi-Head Attention working!\")\n</pre> # Test Multi-Head Attention d_model = 512 num_heads = 8 seq_len = 10 batch_size = 2  mha = MultiHeadAttention(d_model, num_heads) x = torch.randn(batch_size, seq_len, d_model)  output, attn_weights = mha(x, x, x)  # Self-attention  print(f\"Input shape: {x.shape}\") print(f\"Output shape: {output.shape}\") print(f\"Attention weights shape: {attn_weights.shape}\") print(f\"\\n\u2705 Multi-Head Attention working!\") In\u00a0[\u00a0]: Copied! <pre>class PositionalEncoding(nn.Module):\n    \"\"\"Sinusoidal positional encoding.\"\"\"\n    \n    def __init__(self, d_model, max_seq_len=5000):\n        super().__init__()\n        \n        # Create positional encoding matrix\n        pe = torch.zeros(max_seq_len, d_model)\n        position = torch.arange(0, max_seq_len).unsqueeze(1).float()\n        \n        # Compute the div term\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2).float() * \n            (-math.log(10000.0) / d_model)\n        )\n        \n        # Apply sin to even indices, cos to odd indices\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        \n        # Add batch dimension and register as buffer\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n        \n    def forward(self, x):\n        \"\"\"Add positional encoding to input.\"\"\"\n        return x + self.pe[:, :x.size(1), :]\n</pre> class PositionalEncoding(nn.Module):     \"\"\"Sinusoidal positional encoding.\"\"\"          def __init__(self, d_model, max_seq_len=5000):         super().__init__()                  # Create positional encoding matrix         pe = torch.zeros(max_seq_len, d_model)         position = torch.arange(0, max_seq_len).unsqueeze(1).float()                  # Compute the div term         div_term = torch.exp(             torch.arange(0, d_model, 2).float() *              (-math.log(10000.0) / d_model)         )                  # Apply sin to even indices, cos to odd indices         pe[:, 0::2] = torch.sin(position * div_term)         pe[:, 1::2] = torch.cos(position * div_term)                  # Add batch dimension and register as buffer         pe = pe.unsqueeze(0)         self.register_buffer('pe', pe)              def forward(self, x):         \"\"\"Add positional encoding to input.\"\"\"         return x + self.pe[:, :x.size(1), :] In\u00a0[\u00a0]: Copied! <pre># Visualize positional encoding\npe_module = PositionalEncoding(d_model=64, max_seq_len=100)\npe_matrix = pe_module.pe.squeeze().numpy()\n\nplt.figure(figsize=(12, 5))\nplt.imshow(pe_matrix[:50, :].T, cmap='RdBu', aspect='auto')\nplt.colorbar(label='Value')\nplt.xlabel('Position')\nplt.ylabel('Dimension')\nplt.title('Positional Encoding Visualization')\nplt.tight_layout()\nplt.show()\n</pre> # Visualize positional encoding pe_module = PositionalEncoding(d_model=64, max_seq_len=100) pe_matrix = pe_module.pe.squeeze().numpy()  plt.figure(figsize=(12, 5)) plt.imshow(pe_matrix[:50, :].T, cmap='RdBu', aspect='auto') plt.colorbar(label='Value') plt.xlabel('Position') plt.ylabel('Dimension') plt.title('Positional Encoding Visualization') plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>class TransformerBlock(nn.Module):\n    \"\"\"A single Transformer block.\"\"\"\n    \n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n        \n        # Multi-head attention\n        self.attention = MultiHeadAttention(d_model, num_heads)\n        \n        # Feed-forward network\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, d_ff),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_ff, d_model),\n            nn.Dropout(dropout)\n        )\n        \n        # Layer normalization\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        \n        # Dropout\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, mask=None):\n        # Self-attention with residual connection\n        attn_output, _ = self.attention(x, x, x, mask)\n        x = self.norm1(x + self.dropout(attn_output))\n        \n        # Feed-forward with residual connection\n        ffn_output = self.ffn(x)\n        x = self.norm2(x + ffn_output)\n        \n        return x\n</pre> class TransformerBlock(nn.Module):     \"\"\"A single Transformer block.\"\"\"          def __init__(self, d_model, num_heads, d_ff, dropout=0.1):         super().__init__()                  # Multi-head attention         self.attention = MultiHeadAttention(d_model, num_heads)                  # Feed-forward network         self.ffn = nn.Sequential(             nn.Linear(d_model, d_ff),             nn.GELU(),             nn.Dropout(dropout),             nn.Linear(d_ff, d_model),             nn.Dropout(dropout)         )                  # Layer normalization         self.norm1 = nn.LayerNorm(d_model)         self.norm2 = nn.LayerNorm(d_model)                  # Dropout         self.dropout = nn.Dropout(dropout)              def forward(self, x, mask=None):         # Self-attention with residual connection         attn_output, _ = self.attention(x, x, x, mask)         x = self.norm1(x + self.dropout(attn_output))                  # Feed-forward with residual connection         ffn_output = self.ffn(x)         x = self.norm2(x + ffn_output)                  return x In\u00a0[\u00a0]: Copied! <pre># Test the complete Transformer block\nd_model = 512\nnum_heads = 8\nd_ff = 2048\nseq_len = 20\nbatch_size = 4\n\ntransformer_block = TransformerBlock(d_model, num_heads, d_ff)\nx = torch.randn(batch_size, seq_len, d_model)\n\noutput = transformer_block(x)\n\nprint(f\"Input shape: {x.shape}\")\nprint(f\"Output shape: {output.shape}\")\nprint(f\"\\n\u2705 Transformer Block working!\")\n\n# Count parameters\ntotal_params = sum(p.numel() for p in transformer_block.parameters())\nprint(f\"\\nTotal parameters: {total_params:,}\")\n</pre> # Test the complete Transformer block d_model = 512 num_heads = 8 d_ff = 2048 seq_len = 20 batch_size = 4  transformer_block = TransformerBlock(d_model, num_heads, d_ff) x = torch.randn(batch_size, seq_len, d_model)  output = transformer_block(x)  print(f\"Input shape: {x.shape}\") print(f\"Output shape: {output.shape}\") print(f\"\\n\u2705 Transformer Block working!\")  # Count parameters total_params = sum(p.numel() for p in transformer_block.parameters()) print(f\"\\nTotal parameters: {total_params:,}\")"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#what-youll-learn","title":"\ud83d\udcda What You'll Learn\u00b6","text":"<ul> <li>Self-attention mechanism explained</li> <li>Multi-head attention implementation</li> <li>Positional encoding strategies</li> <li>Complete Transformer block in PyTorch</li> </ul> <p>Prerequisites: Basic understanding of vector embeddings and matrix multiplication. We'll use PyTorch for implementation.</p>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#setup","title":"\ud83d\udd27 Setup\u00b6","text":"<p>First, let's install and import the necessary libraries.</p>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#1-the-self-attention-mechanism","title":"1. The Self-Attention Mechanism\u00b6","text":"<p>At the core of the Transformer is the self-attention mechanism. It allows the model to weigh the importance of different words in a sentence when encoding a specific word.</p>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#the-attention-formula","title":"The Attention Formula\u00b6","text":"<p>$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$</p> <p>Where:</p> <ul> <li>Q (Query): What we're looking for</li> <li>K (Key): What we match against</li> <li>V (Value): What we retrieve</li> <li>d_k: Dimension of keys (for scaling)</li> </ul>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#2-multi-head-attention","title":"2. Multi-Head Attention\u00b6","text":"<p>Multi-head attention runs the attention mechanism multiple times in parallel with different learned projections. This allows the model to attend to information from different representation subspaces.</p> <p>$$\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O$$</p> <p>where $\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$</p>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#3-positional-encoding","title":"3. Positional Encoding\u00b6","text":"<p>Since transformers process all positions in parallel, we need to inject information about token positions. We use sinusoidal positional encoding:</p> <p>$$PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$$ $$PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$$</p>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#4-complete-transformer-block","title":"4. Complete Transformer Block\u00b6","text":"<p>A Transformer block combines:</p> <ol> <li>Multi-Head Self-Attention</li> <li>Layer Normalization</li> <li>Feed-Forward Network</li> <li>Residual Connections</li> </ol>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#key-takeaways","title":"\ud83c\udfaf Key Takeaways\u00b6","text":"<ol> <li>Self-Attention lets each token attend to all other tokens in parallel</li> <li>Multi-Head Attention learns multiple attention patterns simultaneously</li> <li>Positional Encoding injects sequence order information</li> <li>Transformer Blocks combine attention, FFN, and residual connections</li> </ol> <p>\ud83d\udca1 Optimization Tip: When running on production data, always ensure your input tensors are on the GPU by calling <code>.to('cuda')</code> on your model and data.</p>"},{"location":"paths/engineering-ai/1.1-transformer-architecture/#next-steps","title":"\ud83d\udcd6 Next Steps\u00b6","text":"<p>Continue to Module 2: Tokenization &amp; Embeddings to learn how text is converted to the vectors that Transformers process.</p> <p>\u00a9 2026 MadeForAI. Learn more at madeforai.github.io</p>"},{"location":"paths/researching-ai/","title":"Researching AI","text":"biotech Researching AI <p>Push the boundaries of AI innovation</p> <p>Explore cutting-edge research, learn to read and implement papers, and contribute to the field. Develop the skills to design novel architectures and conduct rigorous experiments.</p> Learning Modules schedule Coming Soon <p>This learning path is under development. Check back soon for updates!</p>"},{"location":"paths/understanding-ai/","title":"Understanding AI","text":"school Understanding AI <p>Build a solid foundation in AI fundamentals</p> <p>Master the core concepts of artificial intelligence, machine learning, and deep learning. Build your first models and understand how modern AI systems work through hands-on interactive lessons.</p> Learning Modules 1 1 - Foundations play_circle 1.1 - Introduction to AI, ML, and Deep Learning play_circle 1.2 - Your First Neural Network"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/","title":"1.1 - Introduction to AI, ML, and Deep Learning","text":"1.1 - Introduction to AI, ML, and Deep Learning\u00b6              Open in Colab          <p>Welcome to your first step in the AI journey! In this chapter, we'll explore the foundations of Artificial Intelligence, Machine Learning, and Deep Learning. You'll understand how these concepts relate to each other and build your first simple ML model.</p> In\u00a0[\u00a0]: Copied! <pre># Install required packages (uncomment if running in Colab)\n# !pip install numpy matplotlib scikit-learn -q\n</pre> # Install required packages (uncomment if running in Colab) # !pip install numpy matplotlib scikit-learn -q In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Set style for better-looking plots\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 11\n\nprint(f\"NumPy version: {np.__version__}\")\nprint(\"Setup complete!\")\n</pre> import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split  # Set style for better-looking plots plt.style.use('seaborn-v0_8-darkgrid') plt.rcParams['figure.figsize'] = (10, 6) plt.rcParams['font.size'] = 11  print(f\"NumPy version: {np.__version__}\") print(\"Setup complete!\") In\u00a0[\u00a0]: Copied! <pre># Let's visualize the ML paradigms\nparadigms = {\n    ' Supervised Learning': {\n        'description': 'Learning from labeled data (input \u2192 output pairs)',\n        'examples': ['Classification', 'Regression'],\n        'use_cases': ['Spam detection', 'House price prediction', 'Image recognition']\n    },\n    ' Unsupervised Learning': {\n        'description': 'Finding patterns in unlabeled data',\n        'examples': ['Clustering', 'Dimensionality Reduction'],\n        'use_cases': ['Customer segmentation', 'Anomaly detection', 'Data compression']\n    },\n    ' Reinforcement Learning': {\n        'description': 'Learning through trial and error with rewards',\n        'examples': ['Q-Learning', 'Policy Gradients'],\n        'use_cases': ['Game playing (AlphaGo)', 'Robotics', 'Self-driving cars']\n    }\n}\n\nfor paradigm, info in paradigms.items():\n    print(f\"\\n{paradigm}\")\n    print(f\"   {info['description']}\")\n    print(f\"   Examples: {', '.join(info['examples'])}\")\n    print(f\"   Use Cases: {', '.join(info['use_cases'])}\")\n</pre> # Let's visualize the ML paradigms paradigms = {     ' Supervised Learning': {         'description': 'Learning from labeled data (input \u2192 output pairs)',         'examples': ['Classification', 'Regression'],         'use_cases': ['Spam detection', 'House price prediction', 'Image recognition']     },     ' Unsupervised Learning': {         'description': 'Finding patterns in unlabeled data',         'examples': ['Clustering', 'Dimensionality Reduction'],         'use_cases': ['Customer segmentation', 'Anomaly detection', 'Data compression']     },     ' Reinforcement Learning': {         'description': 'Learning through trial and error with rewards',         'examples': ['Q-Learning', 'Policy Gradients'],         'use_cases': ['Game playing (AlphaGo)', 'Robotics', 'Self-driving cars']     } }  for paradigm, info in paradigms.items():     print(f\"\\n{paradigm}\")     print(f\"   {info['description']}\")     print(f\"   Examples: {', '.join(info['examples'])}\")     print(f\"   Use Cases: {', '.join(info['use_cases'])}\") In\u00a0[\u00a0]: Copied! <pre># Generate synthetic house data\nnp.random.seed(42)\n\n# House sizes (square feet)\nsizes = np.random.randint(500, 3500, 100).reshape(-1, 1)\n\n# Prices (with some realistic noise)\n# True relationship: Price = 150 * Size + 50000 + noise\nprices = 150 * sizes + 50000 + np.random.randn(100, 1) * 20000\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    sizes, prices, test_size=0.2, random_state=42\n)\n\nprint(f\"Training samples: {len(X_train)}\")\nprint(f\"Testing samples: {len(X_test)}\")\nprint(f\"\\nSample data:\")\nprint(f\"Size: {X_train[0][0]:.0f} sq ft \u2192 Price: ${y_train[0][0]:,.0f}\")\n</pre> # Generate synthetic house data np.random.seed(42)  # House sizes (square feet) sizes = np.random.randint(500, 3500, 100).reshape(-1, 1)  # Prices (with some realistic noise) # True relationship: Price = 150 * Size + 50000 + noise prices = 150 * sizes + 50000 + np.random.randn(100, 1) * 20000  # Split into training and testing sets X_train, X_test, y_train, y_test = train_test_split(     sizes, prices, test_size=0.2, random_state=42 )  print(f\"Training samples: {len(X_train)}\") print(f\"Testing samples: {len(X_test)}\") print(f\"\\nSample data:\") print(f\"Size: {X_train[0][0]:.0f} sq ft \u2192 Price: ${y_train[0][0]:,.0f}\") In\u00a0[\u00a0]: Copied! <pre># Visualize the data\nplt.figure(figsize=(12, 6))\n\nplt.scatter(X_train, y_train, alpha=0.6, c='#3b82f6', \n           edgecolors='white', s=80, label='Training Data')\nplt.scatter(X_test, y_test, alpha=0.6, c='#f59e0b', \n           edgecolors='white', s=80, label='Test Data')\n\nplt.xlabel('House Size (sq ft)', fontsize=13, fontweight='bold')\nplt.ylabel('Price ($)', fontsize=13, fontweight='bold')\nplt.title('House Prices vs Size', fontsize=15, fontweight='bold', pad=20)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\" Our goal: Find the best line that fits this data!\")\n</pre> # Visualize the data plt.figure(figsize=(12, 6))  plt.scatter(X_train, y_train, alpha=0.6, c='#3b82f6',             edgecolors='white', s=80, label='Training Data') plt.scatter(X_test, y_test, alpha=0.6, c='#f59e0b',             edgecolors='white', s=80, label='Test Data')  plt.xlabel('House Size (sq ft)', fontsize=13, fontweight='bold') plt.ylabel('Price ($)', fontsize=13, fontweight='bold') plt.title('House Prices vs Size', fontsize=15, fontweight='bold', pad=20) plt.legend(fontsize=11) plt.grid(True, alpha=0.3) plt.tight_layout() plt.show()  print(\" Our goal: Find the best line that fits this data!\") In\u00a0[\u00a0]: Copied! <pre># Create and train the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Get the learned parameters\nslope = model.coef_[0][0]\nintercept = model.intercept_[0]\n\nprint(\" Model Training Complete!\\n\")\nprint(f\"Learned equation: Price = {slope:.2f} \u00d7 Size + {intercept:,.0f}\")\nprint(f\"\\nInterpretation:\")\nprint(f\"  \u2022 Base price: ${intercept:,.0f}\")\nprint(f\"  \u2022 Price per sq ft: ${slope:.2f}\")\nprint(f\"\\n This means each additional square foot adds ${slope:.2f} to the price!\")\n</pre> # Create and train the model model = LinearRegression() model.fit(X_train, y_train)  # Get the learned parameters slope = model.coef_[0][0] intercept = model.intercept_[0]  print(\" Model Training Complete!\\n\") print(f\"Learned equation: Price = {slope:.2f} \u00d7 Size + {intercept:,.0f}\") print(f\"\\nInterpretation:\") print(f\"  \u2022 Base price: ${intercept:,.0f}\") print(f\"  \u2022 Price per sq ft: ${slope:.2f}\") print(f\"\\n This means each additional square foot adds ${slope:.2f} to the price!\") In\u00a0[\u00a0]: Copied! <pre># Evaluate the model\ntrain_score = model.score(X_train, y_train)\ntest_score = model.score(X_test, y_test)\n\nprint(f\"Model Performance (R\u00b2 Score):\")\nprint(f\"  Training: {train_score:.4f}\")\nprint(f\"  Testing:  {test_score:.4f}\")\nprint(f\"\\n A score close to 1.0 means excellent predictions!\")\n</pre> # Evaluate the model train_score = model.score(X_train, y_train) test_score = model.score(X_test, y_test)  print(f\"Model Performance (R\u00b2 Score):\") print(f\"  Training: {train_score:.4f}\") print(f\"  Testing:  {test_score:.4f}\") print(f\"\\n A score close to 1.0 means excellent predictions!\") In\u00a0[\u00a0]: Copied! <pre># Visualize predictions\nplt.figure(figsize=(12, 6))\n\n# Plot data points\nplt.scatter(X_train, y_train, alpha=0.6, c='#3b82f6', \n           edgecolors='white', s=80, label='Training Data')\nplt.scatter(X_test, y_test, alpha=0.6, c='#f59e0b', \n           edgecolors='white', s=80, label='Test Data')\n\n# Plot the learned line\nX_line = np.linspace(sizes.min(), sizes.max(), 100).reshape(-1, 1)\ny_line = model.predict(X_line)\nplt.plot(X_line, y_line, 'r-', linewidth=3, label='Learned Model', alpha=0.8)\n\nplt.xlabel('House Size (sq ft)', fontsize=13, fontweight='bold')\nplt.ylabel('Price ($)', fontsize=13, fontweight='bold')\nplt.title('Linear Regression: Predictions vs Actual', fontsize=15, fontweight='bold', pad=20)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n</pre> # Visualize predictions plt.figure(figsize=(12, 6))  # Plot data points plt.scatter(X_train, y_train, alpha=0.6, c='#3b82f6',             edgecolors='white', s=80, label='Training Data') plt.scatter(X_test, y_test, alpha=0.6, c='#f59e0b',             edgecolors='white', s=80, label='Test Data')  # Plot the learned line X_line = np.linspace(sizes.min(), sizes.max(), 100).reshape(-1, 1) y_line = model.predict(X_line) plt.plot(X_line, y_line, 'r-', linewidth=3, label='Learned Model', alpha=0.8)  plt.xlabel('House Size (sq ft)', fontsize=13, fontweight='bold') plt.ylabel('Price ($)', fontsize=13, fontweight='bold') plt.title('Linear Regression: Predictions vs Actual', fontsize=15, fontweight='bold', pad=20) plt.legend(fontsize=11) plt.grid(True, alpha=0.3) plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># Predict prices for new houses\nnew_houses = np.array([[1000], [1500], [2000], [2500], [3000]])\npredicted_prices = model.predict(new_houses)\n\nprint(\" Price Predictions for New Houses:\\n\")\nprint(\"Size (sq ft)  \u2192  Predicted Price\")\nprint(\"\" * 40)\nfor size, price in zip(new_houses, predicted_prices):\n    print(f\"{size[0]:&gt;6,} sq ft  \u2192  ${price[0]:&gt;12,.0f}\")\n</pre> # Predict prices for new houses new_houses = np.array([[1000], [1500], [2000], [2500], [3000]]) predicted_prices = model.predict(new_houses)  print(\" Price Predictions for New Houses:\\n\") print(\"Size (sq ft)  \u2192  Predicted Price\") print(\"\" * 40) for size, price in zip(new_houses, predicted_prices):     print(f\"{size[0]:&gt;6,} sq ft  \u2192  ${price[0]:&gt;12,.0f}\")"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#what-youll-learn","title":"What You'll Learn\u00b6","text":"<ul> <li>What is Artificial Intelligence?</li> <li>The relationship between AI, ML, and DL</li> <li>Key ML paradigms (Supervised, Unsupervised, Reinforcement)</li> <li>Build a simple linear regression model</li> <li>The GenAI landscape in 2026</li> </ul>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#setup","title":"Setup\u00b6","text":"<p>First, let's install and import the libraries we'll need.</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#1-what-is-artificial-intelligence","title":"1. What is Artificial Intelligence?\u00b6","text":"<p>Artificial Intelligence (AI) is the field of computer science focused on creating systems that can perform tasks that typically require human intelligence.</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#the-ai-hierarchy","title":"The AI Hierarchy\u00b6","text":"<p>Think of AI as a set of nested concepts:</p> <pre><code>\n   Artificial Intelligence (AI)       \u2190 Broad field: Any intelligent behavior\n    \n     Machine Learning (ML)           \u2190 Learning from data\n        \n       Deep Learning (DL)          \u2190 Neural networks with many layers\n            \n        GenAI / LLMs             \u2190 Generative models (GPT, Claude, etc.)\n            \n        \n    \n\n</code></pre> <p>Key Insight: All Deep Learning is Machine Learning, all Machine Learning is AI, but not all AI is Machine Learning!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#2-machine-learning-paradigms","title":"2. Machine Learning Paradigms\u00b6","text":"<p>Machine Learning can be categorized into three main paradigms based on how the model learns:</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#3-your-first-ml-model-linear-regression","title":"3. Your First ML Model: Linear Regression\u00b6","text":"<p>Let's build a simple supervised learning model to predict house prices based on size. This is a classic regression problem.</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#the-problem","title":"The Problem\u00b6","text":"<p>Given the size of a house (in square feet), can we predict its price?</p> <p>We'll use the formula: Price = m \u00d7 Size + b</p> <p>Where:</p> <ul> <li>m = slope (how much price increases per square foot)</li> <li>b = intercept (base price)</li> </ul>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#training-the-model","title":"Training the Model\u00b6","text":"<p>Now let's train a linear regression model to learn the relationship between size and price.</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#making-predictions","title":"Making Predictions\u00b6","text":"<p>Now let's use our trained model to predict prices for new houses!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#4-from-ml-to-deep-learning","title":"4. From ML to Deep Learning\u00b6","text":"<p>Linear regression is simple, but what if the relationship isn't linear? That's where Deep Learning comes in!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#key-differences","title":"Key Differences\u00b6","text":"Aspect Traditional ML Deep Learning Model Simple (linear, trees) Neural networks with many layers Features Manual engineering Automatic learning Data Needed Works with small data Needs large datasets Complexity Simple patterns Complex patterns Examples Linear regression, SVM CNNs, Transformers, LLMs"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#neural-network-visualization","title":"Neural Network Visualization\u00b6","text":"<pre><code>Input Layer    Hidden Layers    Output Layer\n                                    \n               \n                                          \n                       \n</code></pre> <p>Each connection has a weight that the network learns during training!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#5-the-genai-landscape-2026","title":"5. The GenAI Landscape (2026)\u00b6","text":"<p>Today's Generative AI ecosystem is built on deep learning, specifically Transformer architectures.</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#popular-models","title":"Popular Models\u00b6","text":"Category Examples Key Features Large Language Models GPT-4, Claude, Gemini Text generation, reasoning, coding Small Language Models Phi-3, Gemma, Qwen Efficient, edge-deployable Multimodal Models GPT-4V, Gemini Pro Vision + Language Code Models Codex, StarCoder, CodeLlama Specialized for programming Open Source Llama 3, Mistral, Mixtral Community-driven, customizable"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#how-llms-work-simplified","title":"How LLMs Work (Simplified)\u00b6","text":"<ol> <li>Training: Learn patterns from billions of text examples</li> <li>Tokenization: Break text into pieces (tokens)</li> <li>Prediction: Predict the next token based on context</li> <li>Generation: Repeat to generate full responses</li> </ol> <p>We'll dive deeper into these concepts in later modules!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#key-takeaways","title":"Key Takeaways\u00b6","text":"<ol> <li>AI is the broad field; ML learns from data; DL uses neural networks</li> <li>Supervised learning uses labeled data (like our house price example)</li> <li>The core ML loop: Data \u2192 Model \u2192 Training \u2192 Predictions</li> <li>Deep Learning adds layers and complexity for harder problems</li> <li>LLMs are the frontier of GenAI, built on transformer architectures</li> </ol>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#next-steps","title":"Next Steps\u00b6","text":"<p>Continue to Chapter 2: Your First Neural Network to build a real neural network from scratch!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.1-ai-ml-intro/#practice-exercise","title":"Practice Exercise\u00b6","text":"<p>Try modifying the code above to:</p> <ol> <li>Change the relationship between size and price</li> <li>Add more features (e.g., number of bedrooms)</li> <li>Experiment with different train/test splits</li> </ol> <p>\u00a9 2026 MadeForAI. Learn more at madeforai.github.io</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/","title":"1.2 - Your First Neural Network","text":"1.2 - Your First Neural Network\u00b6              Open in Colab          <p>In the previous chapter, we built a simple linear model. Now, let's level up and build a real neural network from scratch! You'll understand how neurons work, how networks learn through backpropagation, and build a classifier for handwritten digits.</p> In\u00a0[\u00a0]: Copied! <pre># Install required packages (uncomment if running in Colab)\n# !pip install numpy matplotlib scikit-learn -q\n</pre> # Install required packages (uncomment if running in Colab) # !pip install numpy matplotlib scikit-learn -q In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Set style\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\" Setup complete!\")\n</pre> import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import load_digits from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler  # Set style plt.style.use('seaborn-v0_8-darkgrid') plt.rcParams['figure.figsize'] = (12, 6)  print(\" Setup complete!\") In\u00a0[\u00a0]: Copied! <pre>def sigmoid(x):\n    \"\"\"Sigmoid: Squashes values between 0 and 1\"\"\"\n    return 1 / (1 + np.exp(-x))\n\ndef relu(x):\n    \"\"\"ReLU: Returns max(0, x)\"\"\"\n    return np.maximum(0, x)\n\ndef tanh(x):\n    \"\"\"Tanh: Squashes values between -1 and 1\"\"\"\n    return np.tanh(x)\n\n# Visualize activation functions\nx = np.linspace(-5, 5, 100)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Sigmoid\naxes[0].plot(x, sigmoid(x), 'b-', linewidth=2.5)\naxes[0].set_title('Sigmoid', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('x')\naxes[0].set_ylabel('\u03c3(x)')\naxes[0].grid(True, alpha=0.3)\naxes[0].axhline(y=0, color='k', linestyle='--', alpha=0.3)\naxes[0].axvline(x=0, color='k', linestyle='--', alpha=0.3)\n\n# ReLU\naxes[1].plot(x, relu(x), 'g-', linewidth=2.5)\naxes[1].set_title('ReLU', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('x')\naxes[1].set_ylabel('ReLU(x)')\naxes[1].grid(True, alpha=0.3)\naxes[1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\naxes[1].axvline(x=0, color='k', linestyle='--', alpha=0.3)\n\n# Tanh\naxes[2].plot(x, tanh(x), 'r-', linewidth=2.5)\naxes[2].set_title('Tanh', fontsize=14, fontweight='bold')\naxes[2].set_xlabel('x')\naxes[2].set_ylabel('tanh(x)')\naxes[2].grid(True, alpha=0.3)\naxes[2].axhline(y=0, color='k', linestyle='--', alpha=0.3)\naxes[2].axvline(x=0, color='k', linestyle='--', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\" Activation Functions:\")\nprint(\"  \u2022 Sigmoid: Good for binary classification (0-1 output)\")\nprint(\"  \u2022 ReLU: Most popular for hidden layers (fast, simple)\")\nprint(\"  \u2022 Tanh: Similar to sigmoid but centered at 0\")\n</pre> def sigmoid(x):     \"\"\"Sigmoid: Squashes values between 0 and 1\"\"\"     return 1 / (1 + np.exp(-x))  def relu(x):     \"\"\"ReLU: Returns max(0, x)\"\"\"     return np.maximum(0, x)  def tanh(x):     \"\"\"Tanh: Squashes values between -1 and 1\"\"\"     return np.tanh(x)  # Visualize activation functions x = np.linspace(-5, 5, 100)  fig, axes = plt.subplots(1, 3, figsize=(15, 4))  # Sigmoid axes[0].plot(x, sigmoid(x), 'b-', linewidth=2.5) axes[0].set_title('Sigmoid', fontsize=14, fontweight='bold') axes[0].set_xlabel('x') axes[0].set_ylabel('\u03c3(x)') axes[0].grid(True, alpha=0.3) axes[0].axhline(y=0, color='k', linestyle='--', alpha=0.3) axes[0].axvline(x=0, color='k', linestyle='--', alpha=0.3)  # ReLU axes[1].plot(x, relu(x), 'g-', linewidth=2.5) axes[1].set_title('ReLU', fontsize=14, fontweight='bold') axes[1].set_xlabel('x') axes[1].set_ylabel('ReLU(x)') axes[1].grid(True, alpha=0.3) axes[1].axhline(y=0, color='k', linestyle='--', alpha=0.3) axes[1].axvline(x=0, color='k', linestyle='--', alpha=0.3)  # Tanh axes[2].plot(x, tanh(x), 'r-', linewidth=2.5) axes[2].set_title('Tanh', fontsize=14, fontweight='bold') axes[2].set_xlabel('x') axes[2].set_ylabel('tanh(x)') axes[2].grid(True, alpha=0.3) axes[2].axhline(y=0, color='k', linestyle='--', alpha=0.3) axes[2].axvline(x=0, color='k', linestyle='--', alpha=0.3)  plt.tight_layout() plt.show()  print(\" Activation Functions:\") print(\"  \u2022 Sigmoid: Good for binary classification (0-1 output)\") print(\"  \u2022 ReLU: Most popular for hidden layers (fast, simple)\") print(\"  \u2022 Tanh: Similar to sigmoid but centered at 0\") In\u00a0[\u00a0]: Copied! <pre>class SimpleNeuralNetwork:\n    \"\"\"A simple 2-layer neural network\"\"\"\n    \n    def __init__(self, input_size, hidden_size, output_size):\n        # Initialize weights randomly\n        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n        self.b1 = np.zeros((1, hidden_size))\n        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n        self.b2 = np.zeros((1, output_size))\n        \n    def forward(self, X):\n        \"\"\"Forward pass through the network\"\"\"\n        # Hidden layer\n        self.z1 = np.dot(X, self.W1) + self.b1\n        self.a1 = relu(self.z1)\n        \n        # Output layer\n        self.z2 = np.dot(self.a1, self.W2) + self.b2\n        self.a2 = self.softmax(self.z2)\n        \n        return self.a2\n    \n    def softmax(self, x):\n        \"\"\"Softmax activation for multi-class classification\"\"\"\n        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n    \n    def backward(self, X, y, learning_rate=0.01):\n        \"\"\"Backward pass (gradient descent)\"\"\"\n        m = X.shape[0]\n        \n        # Output layer gradients\n        dz2 = self.a2 - y\n        dW2 = np.dot(self.a1.T, dz2) / m\n        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n        \n        # Hidden layer gradients\n        dz1 = np.dot(dz2, self.W2.T) * (self.z1 &gt; 0)  # ReLU derivative\n        dW1 = np.dot(X.T, dz1) / m\n        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n        \n        # Update weights\n        self.W2 -= learning_rate * dW2\n        self.b2 -= learning_rate * db2\n        self.W1 -= learning_rate * dW1\n        self.b1 -= learning_rate * db1\n    \n    def compute_loss(self, y_true, y_pred):\n        \"\"\"Cross-entropy loss\"\"\"\n        m = y_true.shape[0]\n        log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)])\n        return np.sum(log_likelihood) / m\n    \n    def predict(self, X):\n        \"\"\"Make predictions\"\"\"\n        output = self.forward(X)\n        return np.argmax(output, axis=1)\n\nprint(\" Neural Network class defined!\")\n</pre> class SimpleNeuralNetwork:     \"\"\"A simple 2-layer neural network\"\"\"          def __init__(self, input_size, hidden_size, output_size):         # Initialize weights randomly         self.W1 = np.random.randn(input_size, hidden_size) * 0.01         self.b1 = np.zeros((1, hidden_size))         self.W2 = np.random.randn(hidden_size, output_size) * 0.01         self.b2 = np.zeros((1, output_size))              def forward(self, X):         \"\"\"Forward pass through the network\"\"\"         # Hidden layer         self.z1 = np.dot(X, self.W1) + self.b1         self.a1 = relu(self.z1)                  # Output layer         self.z2 = np.dot(self.a1, self.W2) + self.b2         self.a2 = self.softmax(self.z2)                  return self.a2          def softmax(self, x):         \"\"\"Softmax activation for multi-class classification\"\"\"         exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))         return exp_x / np.sum(exp_x, axis=1, keepdims=True)          def backward(self, X, y, learning_rate=0.01):         \"\"\"Backward pass (gradient descent)\"\"\"         m = X.shape[0]                  # Output layer gradients         dz2 = self.a2 - y         dW2 = np.dot(self.a1.T, dz2) / m         db2 = np.sum(dz2, axis=0, keepdims=True) / m                  # Hidden layer gradients         dz1 = np.dot(dz2, self.W2.T) * (self.z1 &gt; 0)  # ReLU derivative         dW1 = np.dot(X.T, dz1) / m         db1 = np.sum(dz1, axis=0, keepdims=True) / m                  # Update weights         self.W2 -= learning_rate * dW2         self.b2 -= learning_rate * db2         self.W1 -= learning_rate * dW1         self.b1 -= learning_rate * db1          def compute_loss(self, y_true, y_pred):         \"\"\"Cross-entropy loss\"\"\"         m = y_true.shape[0]         log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)])         return np.sum(log_likelihood) / m          def predict(self, X):         \"\"\"Make predictions\"\"\"         output = self.forward(X)         return np.argmax(output, axis=1)  print(\" Neural Network class defined!\") In\u00a0[\u00a0]: Copied! <pre># Load digits dataset (8x8 images)\ndigits = load_digits()\nX, y = digits.data, digits.target\n\n# Normalize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# One-hot encode labels\ny_onehot = np.eye(10)[y]\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y_onehot, test_size=0.2, random_state=42\n)\n\nprint(f\"Dataset loaded!\")\nprint(f\"  Training samples: {X_train.shape[0]}\")\nprint(f\"  Test samples: {X_test.shape[0]}\")\nprint(f\"  Input features: {X_train.shape[1]} (8x8 pixels)\")\nprint(f\"  Output classes: {y_train.shape[1]} (digits 0-9)\")\n</pre> # Load digits dataset (8x8 images) digits = load_digits() X, y = digits.data, digits.target  # Normalize features scaler = StandardScaler() X = scaler.fit_transform(X)  # One-hot encode labels y_onehot = np.eye(10)[y]  # Split data X_train, X_test, y_train, y_test = train_test_split(     X, y_onehot, test_size=0.2, random_state=42 )  print(f\"Dataset loaded!\") print(f\"  Training samples: {X_train.shape[0]}\") print(f\"  Test samples: {X_test.shape[0]}\") print(f\"  Input features: {X_train.shape[1]} (8x8 pixels)\") print(f\"  Output classes: {y_train.shape[1]} (digits 0-9)\") In\u00a0[\u00a0]: Copied! <pre># Visualize some examples\nfig, axes = plt.subplots(2, 5, figsize=(12, 5))\naxes = axes.ravel()\n\nfor i in range(10):\n    axes[i].imshow(digits.images[i], cmap='gray')\n    axes[i].set_title(f'Label: {digits.target[i]}', fontsize=12, fontweight='bold')\n    axes[i].axis('off')\n\nplt.suptitle('Sample Handwritten Digits', fontsize=15, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n</pre> # Visualize some examples fig, axes = plt.subplots(2, 5, figsize=(12, 5)) axes = axes.ravel()  for i in range(10):     axes[i].imshow(digits.images[i], cmap='gray')     axes[i].set_title(f'Label: {digits.target[i]}', fontsize=12, fontweight='bold')     axes[i].axis('off')  plt.suptitle('Sample Handwritten Digits', fontsize=15, fontweight='bold', y=1.02) plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># Create network\nnn = SimpleNeuralNetwork(input_size=64, hidden_size=32, output_size=10)\n\n# Training parameters\nepochs = 100\nlearning_rate = 0.1\nlosses = []\n\nprint(\" Training started...\\n\")\n\nfor epoch in range(epochs):\n    # Forward pass\n    output = nn.forward(X_train)\n    \n    # Compute loss\n    loss = nn.compute_loss(y_train, output)\n    losses.append(loss)\n    \n    # Backward pass\n    nn.backward(X_train, y_train, learning_rate)\n    \n    # Print progress\n    if (epoch + 1) % 20 == 0:\n        train_pred = nn.predict(X_train)\n        train_acc = np.mean(train_pred == y_train.argmax(axis=1))\n        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss:.4f} - Accuracy: {train_acc:.4f}\")\n\nprint(\"\\n Training complete!\")\n</pre> # Create network nn = SimpleNeuralNetwork(input_size=64, hidden_size=32, output_size=10)  # Training parameters epochs = 100 learning_rate = 0.1 losses = []  print(\" Training started...\\n\")  for epoch in range(epochs):     # Forward pass     output = nn.forward(X_train)          # Compute loss     loss = nn.compute_loss(y_train, output)     losses.append(loss)          # Backward pass     nn.backward(X_train, y_train, learning_rate)          # Print progress     if (epoch + 1) % 20 == 0:         train_pred = nn.predict(X_train)         train_acc = np.mean(train_pred == y_train.argmax(axis=1))         print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss:.4f} - Accuracy: {train_acc:.4f}\")  print(\"\\n Training complete!\") In\u00a0[\u00a0]: Copied! <pre># Plot training loss\nplt.figure(figsize=(10, 5))\nplt.plot(losses, linewidth=2, color='#3b82f6')\nplt.xlabel('Epoch', fontsize=12, fontweight='bold')\nplt.ylabel('Loss', fontsize=12, fontweight='bold')\nplt.title('Training Loss Over Time', fontsize=14, fontweight='bold', pad=15)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\" Loss decreased from {:.4f} to {:.4f}\".format(losses[0], losses[-1]))\n</pre> # Plot training loss plt.figure(figsize=(10, 5)) plt.plot(losses, linewidth=2, color='#3b82f6') plt.xlabel('Epoch', fontsize=12, fontweight='bold') plt.ylabel('Loss', fontsize=12, fontweight='bold') plt.title('Training Loss Over Time', fontsize=14, fontweight='bold', pad=15) plt.grid(True, alpha=0.3) plt.tight_layout() plt.show()  print(\" Loss decreased from {:.4f} to {:.4f}\".format(losses[0], losses[-1])) In\u00a0[\u00a0]: Copied! <pre># Test accuracy\ntest_pred = nn.predict(X_test)\ntest_acc = np.mean(test_pred == y_test.argmax(axis=1))\n\nprint(f\"\\n Final Results:\")\nprint(f\"  Test Accuracy: {test_acc:.2%}\")\nprint(f\"\\n Our neural network correctly classifies {test_acc:.1%} of handwritten digits!\")\n</pre> # Test accuracy test_pred = nn.predict(X_test) test_acc = np.mean(test_pred == y_test.argmax(axis=1))  print(f\"\\n Final Results:\") print(f\"  Test Accuracy: {test_acc:.2%}\") print(f\"\\n Our neural network correctly classifies {test_acc:.1%} of handwritten digits!\") In\u00a0[\u00a0]: Copied! <pre># Visualize predictions\nfig, axes = plt.subplots(2, 5, figsize=(12, 5))\naxes = axes.ravel()\n\n# Get first 10 test samples\ntest_indices = range(10)\n\nfor i, idx in enumerate(test_indices):\n    # Reshape for visualization\n    image = X_test[idx].reshape(8, 8)\n    \n    # Get prediction\n    pred = test_pred[idx]\n    true = y_test[idx].argmax()\n    \n    # Plot\n    axes[i].imshow(image, cmap='gray')\n    color = 'green' if pred == true else 'red'\n    axes[i].set_title(f'Pred: {pred} | True: {true}', \n                     fontsize=11, fontweight='bold', color=color)\n    axes[i].axis('off')\n\nplt.suptitle('Model Predictions (Green=Correct, Red=Wrong)', \n            fontsize=14, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n</pre> # Visualize predictions fig, axes = plt.subplots(2, 5, figsize=(12, 5)) axes = axes.ravel()  # Get first 10 test samples test_indices = range(10)  for i, idx in enumerate(test_indices):     # Reshape for visualization     image = X_test[idx].reshape(8, 8)          # Get prediction     pred = test_pred[idx]     true = y_test[idx].argmax()          # Plot     axes[i].imshow(image, cmap='gray')     color = 'green' if pred == true else 'red'     axes[i].set_title(f'Pred: {pred} | True: {true}',                       fontsize=11, fontweight='bold', color=color)     axes[i].axis('off')  plt.suptitle('Model Predictions (Green=Correct, Red=Wrong)',              fontsize=14, fontweight='bold', y=1.02) plt.tight_layout() plt.show()"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#what-youll-learn","title":"What You'll Learn\u00b6","text":"<ul> <li>How artificial neurons work</li> <li>Activation functions and why they matter</li> <li>Building a neural network from scratch</li> <li>Training with gradient descent</li> <li>Classifying handwritten digits (MNIST)</li> </ul>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#setup","title":"Setup\u00b6","text":""},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#1-understanding-artificial-neurons","title":"1. Understanding Artificial Neurons\u00b6","text":"<p>An artificial neuron is inspired by biological neurons in the brain. Here's how it works:</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#the-neuron-formula","title":"The Neuron Formula\u00b6","text":"<pre><code>Input \u2192 [Weighted Sum] \u2192 [Activation Function] \u2192 Output\n</code></pre> <p>Mathematically:</p> <p>$$y = f(w_1x_1 + w_2x_2 + ... + w_nx_n + b)$$</p> <p>Where:</p> <ul> <li>x = inputs</li> <li>w = weights (learned parameters)</li> <li>b = bias (learned parameter)</li> <li>f = activation function (adds non-linearity)</li> </ul>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#visual-representation","title":"Visual Representation\u00b6","text":"<pre><code>x\u2081 w\u2081\nx\u2082 w\u2082\nx\u2083 w\u2083 \u03a3  f(\u00b7)  output\n   ...         \u2191\nx\u2099 w\u2099      b (bias)\n</code></pre>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#2-activation-functions","title":"2. Activation Functions\u00b6","text":"<p>Activation functions introduce non-linearity, allowing neural networks to learn complex patterns.</p> <p>Let's implement and visualize the most common ones:</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#3-building-a-neural-network-from-scratch","title":"3. Building a Neural Network from Scratch\u00b6","text":"<p>Let's build a simple 2-layer neural network to classify handwritten digits!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#network-architecture","title":"Network Architecture\u00b6","text":"<pre><code>Input (64 pixels) \u2192 Hidden Layer (32 neurons) \u2192 Output (10 classes)\n</code></pre>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#4-loading-the-mnist-digits-dataset","title":"4. Loading the MNIST Digits Dataset\u00b6","text":"<p>We'll use the classic MNIST dataset of handwritten digits (0-9).</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#5-training-the-neural-network","title":"5. Training the Neural Network\u00b6","text":"<p>Now let's train our network!</p>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#6-evaluating-the-model","title":"6. Evaluating the Model\u00b6","text":""},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#key-takeaways","title":"Key Takeaways\u00b6","text":"<ol> <li>Neurons combine inputs with weights, add bias, and apply activation functions</li> <li>Activation functions (ReLU, Sigmoid, Tanh) add non-linearity</li> <li>Forward pass: Data flows through layers to make predictions</li> <li>Backward pass: Gradients flow back to update weights</li> <li>Training loop: Forward \u2192 Loss \u2192 Backward \u2192 Update (repeat!)</li> </ol>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#whats-next","title":"What's Next?\u00b6","text":"<p>You've built a neural network from scratch! In the next modules, you'll learn:</p> <ul> <li>How modern frameworks (PyTorch, TensorFlow) simplify this</li> <li>Deeper networks with more layers</li> <li>Convolutional networks for images</li> <li>Transformer architectures for language</li> </ul>"},{"location":"paths/understanding-ai/module-1-foundations/1.2-first-neural-network/#practice-exercises","title":"Practice Exercises\u00b6","text":"<p>Try these challenges:</p> <ol> <li>Add another hidden layer to the network</li> <li>Experiment with different learning rates</li> <li>Try different activation functions</li> <li>Increase the hidden layer size</li> </ol> <p>\u00a9 2026 MadeForAI. Learn more at madeforai.github.io</p>"}]}