{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Supervised Learning Essentials\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/madeforai/madeforai/blob/main/docs/understanding-ai/module-2/2.1-supervised-learning.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Master the art of prediction‚Äîfrom house prices to disease diagnosis, supervised learning powers 70% of real-world AI applications.**\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "- **The supervised learning workflow**: From problem formulation to model deployment\n",
    "- **Regression fundamentals**: Predicting continuous values (prices, temperatures, quantities)\n",
    "- **Classification fundamentals**: Predicting categories (spam/not spam, disease/healthy)\n",
    "- **Evaluation metrics that matter**: How to measure success for regression and classification\n",
    "- **Overfitting and regularization**: The #1 challenge in ML and how to fix it\n",
    "\n",
    "## ‚è±Ô∏è Estimated Time\n",
    "35-40 minutes\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Completed Module 1 (especially 1.3 and 1.4)\n",
    "- Understanding of train-test splits and gradient descent\n",
    "- Basic Python and scikit-learn familiarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Welcome to the Workhorse of Machine Learning\n",
    "\n",
    "If unsupervised learning is like exploring a new city without a map, **supervised learning is like having a GPS with turn-by-turn directions**.\n",
    "\n",
    "Here's why supervised learning dominates the ML landscape in 2026:\n",
    "\n",
    "- **70% of industry ML applications** use supervised learning\n",
    "- **Billion-dollar industries** built on it: fraud detection, medical diagnosis, recommendation systems\n",
    "- **Interpretable and reliable**: You know what you're predicting and can measure success\n",
    "- **Data-efficient**: With enough labeled examples, it just works\n",
    "\n",
    "**The Core Idea:**\n",
    "> \"Show me examples of correct input‚Üíoutput pairs, and I'll learn the pattern so well that I can predict the output for new inputs.\"\n",
    "\n",
    "Think of it like learning to grade essays. After seeing 1000 essays with teacher grades (labeled data), you start recognizing patterns: \"Strong thesis = high grade, poor grammar = low grade.\" Eventually, you can grade new essays yourself.\n",
    "\n",
    "That's supervised learning! Let's dive deep. üèä‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Install and import libraries\n",
    "# Uncomment if running in Google Colab\n",
    "# !pip install numpy pandas matplotlib seaborn scikit-learn plotly -q\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    ")\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")\n",
    "print(\"üìò Module 2.1: Supervised Learning Essentials\")\n",
    "print(\"üéØ Let's master prediction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Part 1: Regression - Predicting Numbers\n",
    "\n",
    "### What is Regression?\n",
    "\n",
    "**Regression** predicts a **continuous numerical value** based on input features.\n",
    "\n",
    "**Real-World Examples:**\n",
    "- üè† Predicting house prices from size, location, bedrooms\n",
    "- üìà Forecasting stock prices from historical data\n",
    "- üå°Ô∏è Estimating temperature from weather patterns\n",
    "- üí∞ Predicting customer lifetime value from purchase history\n",
    "- üöó Estimating used car prices from mileage, age, brand\n",
    "\n",
    "**Key Characteristics:**\n",
    "- Output is a **number** (can be any value on a continuous scale)\n",
    "- Examples: $350,000, 23.7¬∞C, $1,245.99\n",
    "- Measured using **distance metrics** (how far off were we?)\n",
    "\n",
    "Let's build a complete regression model from scratch!\n",
    "\n",
    "<!-- [PLACEHOLDER IMAGE]\n",
    "Prompt for image generation:\n",
    "\"Create an educational diagram showing regression concept.\n",
    "Style: Clean, modern, split into 3 panels.\n",
    "Panel 1: Scatter plot of house size vs price with points\n",
    "Panel 2: Same plot with best-fit line drawn through points\n",
    "Panel 3: New house (marked with star) with predicted price shown\n",
    "Elements:\n",
    "- X-axis: House Size (sq ft)\n",
    "- Y-axis: Price ($)\n",
    "- Best-fit line in blue\n",
    "- Training points in gray\n",
    "- New prediction in red star\n",
    "- Arrows showing 'Learn from data' ‚Üí 'Find pattern' ‚Üí 'Predict new'\n",
    "Color scheme: Professional blue and orange gradient.\n",
    "Format: Wide horizontal 16:9 layout.\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üè† Case Study: California Housing Prices\n",
    "\n",
    "We'll predict median house prices in California neighborhoods using features like:\n",
    "- Median income in the area\n",
    "- Average house age\n",
    "- Average number of rooms\n",
    "- Population density\n",
    "- Location (latitude/longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic California housing data (realistic patterns)\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the dataset\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = pd.Series(housing.target, name='MedianHouseValue')\n",
    "\n",
    "# Convert to actual dollar values (multiply by 100,000)\n",
    "y = y * 100000\n",
    "\n",
    "print(\"üè† California Housing Dataset Loaded\\n\")\n",
    "print(f\"Samples: {len(X):,}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"\\nFeature names: {list(X.columns)}\")\n",
    "print(f\"\\nTarget: Median house value in USD\")\n",
    "print(f\"Price range: ${y.min():,.0f} - ${y.max():,.0f}\")\n",
    "print(f\"Average price: ${y.mean():,.0f}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nüìä First 5 samples:\")\n",
    "sample_df = X.head().copy()\n",
    "sample_df['MedianHouseValue'] = y.head()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore relationships between features and price\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Select key features to visualize\n",
    "features_to_plot = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']\n",
    "feature_labels = ['Median Income', 'House Age', 'Avg Rooms', 'Avg Bedrooms', 'Population', 'Avg Occupancy']\n",
    "\n",
    "for idx, (feature, label) in enumerate(zip(features_to_plot, feature_labels)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Scatter plot with transparency\n",
    "    ax.scatter(X[feature], y, alpha=0.3, s=10, color='#3b82f6', edgecolors='none')\n",
    "    \n",
    "    ax.set_xlabel(label, fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Median House Value ($)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{label} vs Price', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Format y-axis\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    corr = np.corrcoef(X[feature], y)[0, 1]\n",
    "    ax.text(0.05, 0.95, f'Correlation: {corr:.2f}', \n",
    "           transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Feature-Price Relationships in California Housing', \n",
    "            fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Key Observations:\")\n",
    "print(\"   ‚Üí Median Income shows strongest positive correlation with price\")\n",
    "print(\"   ‚Üí House age has weak negative correlation (older = slightly cheaper)\")\n",
    "print(\"   ‚Üí Number of rooms positively correlates with price\")\n",
    "print(\"   ‚Üí High population density areas tend to have higher prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìê Building a Linear Regression Model\n",
    "\n",
    "**Linear Regression** is the simplest and most interpretable regression algorithm.\n",
    "\n",
    "**The Math (Don't Panic!):**\n",
    "```\n",
    "y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `y` = predicted value (house price)\n",
    "- `Œ≤‚ÇÄ` = intercept (baseline price)\n",
    "- `Œ≤‚ÇÅ, Œ≤‚ÇÇ, ...` = coefficients (how much each feature affects price)\n",
    "- `x‚ÇÅ, x‚ÇÇ, ...` = feature values (income, age, rooms, etc.)\n",
    "\n",
    "**Goal:** Find the best Œ≤ values that minimize prediction error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Data Split:\")\n",
    "print(f\"   Training: {len(X_train):,} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"   Testing: {len(X_test):,} samples ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "\n",
    "# Feature scaling (important for many algorithms!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Features scaled to mean=0, std=1\")\n",
    "\n",
    "# Train linear regression\n",
    "print(f\"\\nüîß Training Linear Regression...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = lr_model.predict(X_train_scaled)\n",
    "y_test_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"‚úÖ Model trained!\\n\")\n",
    "\n",
    "# Evaluate performance\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"üìä Model Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<20} {'Training':>15} {'Testing':>15}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'R¬≤ Score':<20} {train_r2:>15.4f} {test_r2:>15.4f}\")\n",
    "print(f\"{'RMSE (Root MSE)':<20} ${train_rmse:>14,.0f} ${test_rmse:>14,.0f}\")\n",
    "print(f\"{'MAE (Mean Abs Err)':<20} ${train_mae:>14,.0f} ${test_mae:>14,.0f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   ‚Üí R¬≤ = {test_r2:.1%}: Model explains {test_r2:.1%} of price variation\")\n",
    "print(f\"   ‚Üí On average, predictions are off by ${test_mae:,.0f}\")\n",
    "print(f\"   ‚Üí Training and test scores are similar ‚Üí Good generalization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left: Training set\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.4, s=20, color='#3b82f6', edgecolors='none')\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "        'r--', linewidth=3, label='Perfect Predictions')\n",
    "ax1.set_xlabel('Actual Price ($)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'Training Set Predictions\\n(R¬≤ = {train_r2:.3f})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Right: Test set\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.4, s=20, color='#10b981', edgecolors='none')\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "        'r--', linewidth=3, label='Perfect Predictions')\n",
    "ax2.set_xlabel('Actual Price ($)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Test Set Predictions (Unseen Data!)\\n(R¬≤ = {test_r2:.3f})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "plt.suptitle('Actual vs Predicted House Prices\\n(Points closer to red line = better predictions)', \n",
    "            fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ What This Shows:\")\n",
    "print(\"   ‚Üí Points near the red line = accurate predictions\")\n",
    "print(\"   ‚Üí Points far from the line = prediction errors\")\n",
    "print(\"   ‚Üí Test set (green) shows similar pattern to training (blue)\")\n",
    "print(\"   ‚Üí Model generalizes well to unseen data! ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr_model.coef_,\n",
    "    'Abs_Coefficient': np.abs(lr_model.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Feature Importance (Coefficients):\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    effect = \"increases\" if row['Coefficient'] > 0 else \"decreases\"\n",
    "    print(f\"{row['Feature']:<15}: ${row['Coefficient']:>10,.0f} ({effect} price)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize coefficients\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['#10b981' if c > 0 else '#ef4444' for c in feature_importance['Coefficient']]\n",
    "bars = ax.barh(feature_importance['Feature'], feature_importance['Coefficient'], \n",
    "              color=colors, alpha=0.7, edgecolor='white', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Coefficient Value (Impact on Price)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Feature Impact on House Price\\n(Green = Positive, Red = Negative)', \n",
    "            fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Business Insights:\")\n",
    "print(\"   ‚Üí MedInc (income) is by FAR the strongest predictor\")\n",
    "print(\"   ‚Üí AveOccup (occupancy) negatively affects price (overcrowding)\")\n",
    "print(\"   ‚Üí Latitude matters (location, location, location!)\")\n",
    "print(\"   ‚Üí House age has minimal impact (California market is hot!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Understanding Regression Metrics\n",
    "\n",
    "**3 Key Metrics to Judge Regression Models:**\n",
    "\n",
    "#### 1Ô∏è‚É£ R¬≤ Score (R-Squared)\n",
    "- **Range:** 0 to 1 (1 = perfect, 0 = useless)\n",
    "- **Meaning:** % of variance in target explained by features\n",
    "- **Example:** R¬≤ = 0.60 means \"60% of price variation is explained by our features\"\n",
    "- **Pro:** Easy to interpret, dimensionless\n",
    "- **Con:** Can be misleading with too many features\n",
    "\n",
    "#### 2Ô∏è‚É£ RMSE (Root Mean Squared Error)\n",
    "- **Range:** 0 to ‚àû (0 = perfect)\n",
    "- **Meaning:** Average prediction error in original units\n",
    "- **Example:** RMSE = $69,000 means \"on average, off by $69K\"\n",
    "- **Pro:** Penalizes large errors more (squares before averaging)\n",
    "- **Con:** Sensitive to outliers\n",
    "\n",
    "#### 3Ô∏è‚É£ MAE (Mean Absolute Error)\n",
    "- **Range:** 0 to ‚àû (0 = perfect)\n",
    "- **Meaning:** Average absolute difference from truth\n",
    "- **Example:** MAE = $49,000 means \"typical error is $49K\"\n",
    "- **Pro:** More robust to outliers than RMSE\n",
    "- **Con:** Doesn't differentiate between small and large errors\n",
    "\n",
    "**Which to use?**\n",
    "- Use **R¬≤** for overall model quality\n",
    "- Use **RMSE** if large errors are very bad (e.g., medical dosage)\n",
    "- Use **MAE** for interpretability (\"typical error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Part 2: Classification - Predicting Categories\n",
    "\n",
    "### What is Classification?\n",
    "\n",
    "**Classification** predicts a **discrete category/label** from input features.\n",
    "\n",
    "**Real-World Examples:**\n",
    "- üìß Spam detection (spam vs. not spam)\n",
    "- üè• Disease diagnosis (healthy vs. diseased)\n",
    "- üí≥ Fraud detection (fraudulent vs. legitimate)\n",
    "- üòä Sentiment analysis (positive, neutral, negative)\n",
    "- üê± Image recognition (cat, dog, bird, etc.)\n",
    "\n",
    "**Types of Classification:**\n",
    "- **Binary:** 2 classes (yes/no, 0/1, true/false)\n",
    "- **Multi-class:** 3+ classes, one label (apple, orange, banana)\n",
    "- **Multi-label:** Multiple classes possible (tags: sports, politics, tech)\n",
    "\n",
    "**Key Difference from Regression:**\n",
    "- Regression: \"How much?\" ‚Üí $250,000\n",
    "- Classification: \"Which one?\" ‚Üí Class A\n",
    "\n",
    "<!-- [PLACEHOLDER IMAGE]\n",
    "Prompt for image generation:\n",
    "\"Create an educational diagram showing classification concept.\n",
    "Style: Clean, modern, split into 2 sections.\n",
    "Section 1 (Binary Classification):\n",
    "- Scatter plot with two distinct clusters (red and blue points)\n",
    "- Decision boundary line separating the clusters\n",
    "- Labels: 'Class 0' and 'Class 1'\n",
    "Section 2 (Multi-class Classification):\n",
    "- Scatter plot with three clusters (red, blue, green)\n",
    "- Decision boundaries separating all three classes\n",
    "- Labels: 'Class A', 'Class B', 'Class C'\n",
    "- New unlabeled point (star) being classified\n",
    "Color scheme: Professional, high contrast.\n",
    "Format: Wide horizontal 16:9 layout.\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü©∫ Case Study: Heart Disease Prediction\n",
    "\n",
    "We'll predict whether a patient has heart disease based on:\n",
    "- Age, sex, chest pain type\n",
    "- Resting blood pressure\n",
    "- Cholesterol levels\n",
    "- Maximum heart rate achieved\n",
    "- Exercise-induced angina\n",
    "- And more clinical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic heart disease data\n",
    "np.random.seed(42)\n",
    "n_patients = 1000\n",
    "\n",
    "# Create realistic patient data\n",
    "data = pd.DataFrame({\n",
    "    'age': np.random.randint(30, 80, n_patients),\n",
    "    'sex': np.random.choice([0, 1], n_patients),  # 0=Female, 1=Male\n",
    "    'chest_pain_type': np.random.choice([0, 1, 2, 3], n_patients),\n",
    "    'resting_bp': np.random.randint(90, 200, n_patients),\n",
    "    'cholesterol': np.random.randint(150, 350, n_patients),\n",
    "    'fasting_blood_sugar': np.random.choice([0, 1], n_patients, p=[0.85, 0.15]),\n",
    "    'rest_ecg': np.random.choice([0, 1, 2], n_patients),\n",
    "    'max_heart_rate': np.random.randint(70, 200, n_patients),\n",
    "    'exercise_angina': np.random.choice([0, 1], n_patients, p=[0.7, 0.3]),\n",
    "    'oldpeak': np.random.uniform(0, 6, n_patients),\n",
    "    'slope': np.random.choice([0, 1, 2], n_patients)\n",
    "})\n",
    "\n",
    "# Create target variable (heart disease presence)\n",
    "# Higher probability if: older, male, high BP/cholesterol, lower max HR\n",
    "disease_prob = 0.1  # Base probability\n",
    "disease_prob += (data['age'] > 60) * 0.25\n",
    "disease_prob += (data['sex'] == 1) * 0.20\n",
    "disease_prob += (data['resting_bp'] > 150) * 0.20\n",
    "disease_prob += (data['cholesterol'] > 250) * 0.25\n",
    "disease_prob += (data['max_heart_rate'] < 120) * 0.20\n",
    "disease_prob += (data['exercise_angina'] == 1) * 0.30\n",
    "disease_prob += (data['chest_pain_type'] == 3) * 0.15\n",
    "\n",
    "data['heart_disease'] = (np.random.random(n_patients) < disease_prob).astype(int)\n",
    "\n",
    "print(\"ü©∫ Heart Disease Dataset Created\\n\")\n",
    "print(f\"Total patients: {len(data):,}\")\n",
    "print(f\"Features: {data.shape[1] - 1}\")\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"   No disease (0): {(data['heart_disease']==0).sum()} ({(data['heart_disease']==0).sum()/len(data)*100:.1f}%)\")\n",
    "print(f\"   Has disease (1): {(data['heart_disease']==1).sum()} ({(data['heart_disease']==1).sum()/len(data)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüìä First 5 patients:\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions by class\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "features_to_plot = ['age', 'resting_bp', 'cholesterol', 'max_heart_rate', 'oldpeak', 'chest_pain_type']\n",
    "feature_labels = ['Age', 'Resting BP', 'Cholesterol', 'Max Heart Rate', 'Oldpeak', 'Chest Pain Type']\n",
    "\n",
    "for idx, (feature, label) in enumerate(zip(features_to_plot, feature_labels)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Separate by class\n",
    "    no_disease = data[data['heart_disease'] == 0][feature]\n",
    "    has_disease = data[data['heart_disease'] == 1][feature]\n",
    "    \n",
    "    # Plot histograms\n",
    "    ax.hist(no_disease, bins=30, alpha=0.6, label='No Disease', color='#10b981', edgecolor='white', linewidth=0.5)\n",
    "    ax.hist(has_disease, bins=30, alpha=0.6, label='Has Disease', color='#ef4444', edgecolor='white', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel(label, fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Count', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{label} Distribution by Disease Status', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Feature Distributions: Healthy vs Heart Disease', \n",
    "            fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Key Observations:\")\n",
    "print(\"   ‚Üí Age: Disease patients tend to be older\")\n",
    "print(\"   ‚Üí BP & Cholesterol: Higher values more common in disease patients\")\n",
    "print(\"   ‚Üí Max Heart Rate: Disease patients have lower max heart rates\")\n",
    "print(\"   ‚Üí These patterns will help our classifier distinguish classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Building a Logistic Regression Classifier\n",
    "\n",
    "**Logistic Regression** is the most popular binary classification algorithm.\n",
    "\n",
    "**Despite the name, it's NOT regression‚Äîit's classification!**\n",
    "\n",
    "**How it works:**\n",
    "1. Computes a weighted sum of features (like linear regression)\n",
    "2. Passes result through **sigmoid function** ‚Üí outputs probability (0 to 1)\n",
    "3. If probability > 0.5 ‚Üí Class 1, else ‚Üí Class 0\n",
    "\n",
    "**Sigmoid Function:**\n",
    "```\n",
    "P(y=1) = 1 / (1 + e^(-z))\n",
    "where z = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ...\n",
    "```\n",
    "\n",
    "**Why sigmoid?** It squashes any number into range [0, 1], perfect for probabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = data.drop('heart_disease', axis=1)\n",
    "y = data['heart_disease']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify keeps class balance\n",
    ")\n",
    "\n",
    "print(f\"üìä Data Split:\")\n",
    "print(f\"   Training: {len(X_train):,} patients\")\n",
    "print(f\"   Testing: {len(X_test):,} patients\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Features scaled\")\n",
    "\n",
    "# Train logistic regression\n",
    "print(f\"\\nüîß Training Logistic Regression Classifier...\")\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = clf.predict(X_train_scaled)\n",
    "y_test_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Get probability predictions\n",
    "y_train_proba = clf.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"‚úÖ Model trained!\\n\")\n",
    "\n",
    "# Evaluate performance\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "train_prec = precision_score(y_train, y_train_pred)\n",
    "test_prec = precision_score(y_test, y_test_pred)\n",
    "train_rec = recall_score(y_train, y_train_pred)\n",
    "test_rec = recall_score(y_test, y_test_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"üìä Model Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<20} {'Training':>15} {'Testing':>15}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Accuracy':<20} {train_acc:>15.3f} {test_acc:>15.3f}\")\n",
    "print(f\"{'Precision':<20} {train_prec:>15.3f} {test_prec:>15.3f}\")\n",
    "print(f\"{'Recall':<20} {train_rec:>15.3f} {test_rec:>15.3f}\")\n",
    "print(f\"{'F1-Score':<20} {train_f1:>15.3f} {test_f1:>15.3f}\")\n",
    "print(f\"{'ROC-AUC':<20} {train_auc:>15.3f} {test_auc:>15.3f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüí° Quick Interpretation:\")\n",
    "print(f\"   ‚Üí Accuracy: {test_acc:.1%} of predictions are correct\")\n",
    "print(f\"   ‚Üí Precision: {test_prec:.1%} of predicted disease cases are actual disease\")\n",
    "print(f\"   ‚Üí Recall: {test_rec:.1%} of actual disease cases were caught\")\n",
    "print(f\"   ‚Üí ROC-AUC: {test_auc:.3f} (0.5=random, 1.0=perfect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Understanding Classification Metrics\n",
    "\n",
    "Classification has MORE metrics than regression because different use cases care about different errors!\n",
    "\n",
    "#### 1Ô∏è‚É£ Accuracy\n",
    "**Formula:** (Correct Predictions) / (Total Predictions)\n",
    "- **Pro:** Easy to understand\n",
    "- **Con:** Misleading for imbalanced datasets\n",
    "- **Example:** 99% accuracy sounds great, but if only 1% have disease, predicting \"no disease\" for everyone gives 99% accuracy!\n",
    "\n",
    "#### 2Ô∏è‚É£ Precision\n",
    "**Formula:** True Positives / (True Positives + False Positives)\n",
    "- **Question:** \"Of all predicted disease cases, how many actually have it?\"\n",
    "- **When to prioritize:** When false alarms are expensive (e.g., spam filter)\n",
    "- **Medical example:** Don't want healthy patients unnecessarily treated\n",
    "\n",
    "#### 3Ô∏è‚É£ Recall (Sensitivity)\n",
    "**Formula:** True Positives / (True Positives + False Negatives)\n",
    "- **Question:** \"Of all actual disease cases, how many did we catch?\"\n",
    "- **When to prioritize:** When missing positives is dangerous (e.g., cancer screening)\n",
    "- **Medical example:** Don't want to miss any sick patients\n",
    "\n",
    "#### 4Ô∏è‚É£ F1-Score\n",
    "**Formula:** 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "- **Meaning:** Harmonic mean of precision and recall\n",
    "- **Use:** When you need balance between precision and recall\n",
    "\n",
    "#### 5Ô∏è‚É£ ROC-AUC\n",
    "**Range:** 0.5 (random) to 1.0 (perfect)\n",
    "- **Meaning:** Area under the ROC curve (True Positive Rate vs False Positive Rate)\n",
    "- **Use:** Overall classifier quality, threshold-independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left: Confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True,\n",
    "           xticklabels=['No Disease', 'Has Disease'],\n",
    "           yticklabels=['No Disease', 'Has Disease'],\n",
    "           cbar_kws={'label': 'Count'},\n",
    "           ax=ax1, annot_kws={'size': 14, 'weight': 'bold'})\n",
    "ax1.set_xlabel('Predicted', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Actual', fontsize=13, fontweight='bold')\n",
    "ax1.set_title('Confusion Matrix\\n(Test Set)', fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "# Right: ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "ax2.plot(fpr, tpr, linewidth=3, color='#3b82f6', label=f'Logistic Regression (AUC = {test_auc:.3f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier (AUC = 0.500)')\n",
    "ax2.set_xlabel('False Positive Rate', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('True Positive Rate', fontsize=13, fontweight='bold')\n",
    "ax2.set_title('ROC Curve\\n(Closer to top-left = better)', fontsize=14, fontweight='bold', pad=15)\n",
    "ax2.legend(fontsize=11, loc='lower right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Break down confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nüìä Confusion Matrix Breakdown:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"True Negatives (TN):  {tn:4d} ‚Üê Correctly predicted healthy\")\n",
    "print(f\"False Positives (FP): {fp:4d} ‚Üê Healthy but predicted disease (Type I error)\")\n",
    "print(f\"False Negatives (FN): {fn:4d} ‚Üê Disease but predicted healthy (Type II error) ‚ö†Ô∏è\")\n",
    "print(f\"True Positives (TP):  {tp:4d} ‚Üê Correctly predicted disease\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüí° Medical Implications:\")\n",
    "print(f\"   ‚Üí We correctly identified {tp} disease patients (can treat!)\")\n",
    "print(f\"   ‚Üí We missed {fn} disease patients (dangerous!)\")\n",
    "print(f\"   ‚Üí We had {fp} false alarms (unnecessary worry/tests)\")\n",
    "print(f\"   ‚Üí Recall = {test_rec:.1%}: We catch {test_rec:.1%} of disease cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Part 3: Overfitting and Regularization\n",
    "\n",
    "### The #1 Challenge in Machine Learning\n",
    "\n",
    "**Overfitting** = Model memorizes training data instead of learning patterns\n",
    "\n",
    "**The Problem:**\n",
    "- Training accuracy: 99% ‚úÖ\n",
    "- Test accuracy: 65% ‚ùå\n",
    "\n",
    "**Analogy:** A student who memorizes exact exam questions but can't solve new problems.\n",
    "\n",
    "**Signs of Overfitting:**\n",
    "1. Large gap between training and test performance\n",
    "2. Model performs well on training data, poorly on new data\n",
    "3. Model is too complex for the amount of data\n",
    "\n",
    "**Underfitting** = Opposite problem, model is too simple\n",
    "- Training accuracy: 60% ‚ùå\n",
    "- Test accuracy: 58% ‚ùå\n",
    "\n",
    "**Goal:** Find the sweet spot ‚Üí **Good fit**\n",
    "- Training accuracy: 85% ‚úÖ\n",
    "- Test accuracy: 83% ‚úÖ\n",
    "\n",
    "<!-- [PLACEHOLDER IMAGE]\n",
    "Prompt for image generation:\n",
    "\"Create an educational diagram showing overfitting, underfitting, and good fit.\n",
    "Style: Clean, modern, three panels side-by-side.\n",
    "Panel 1 - Underfitting:\n",
    "- Scatter plot with curved data pattern\n",
    "- Simple straight line that doesn't capture the curve\n",
    "- Label: 'Too Simple - High Bias'\n",
    "Panel 2 - Good Fit:\n",
    "- Same data\n",
    "- Smooth curve that follows the pattern\n",
    "- Label: 'Just Right - Balanced'\n",
    "Panel 3 - Overfitting:\n",
    "- Same data\n",
    "- Extremely wiggly line passing through every point\n",
    "- Label: 'Too Complex - High Variance'\n",
    "Color scheme: Red (underfitting), Green (good fit), Blue (overfitting).\n",
    "Format: Wide horizontal 16:9 layout.\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíä The Cure: Regularization\n",
    "\n",
    "**Regularization** = Adding a penalty for model complexity\n",
    "\n",
    "**How it works:**\n",
    "```\n",
    "Old loss function: Loss = Error on training data\n",
    "New loss function: Loss = Error on training data + Œª √ó (Model Complexity)\n",
    "```\n",
    "\n",
    "Where Œª (lambda) = regularization strength (hyperparameter you tune)\n",
    "\n",
    "**Two Popular Types:**\n",
    "\n",
    "#### üÖª1Ô∏è‚É£ L1 Regularization (Lasso)\n",
    "- Penalty = sum of absolute values of coefficients\n",
    "- **Effect:** Drives some coefficients to EXACTLY zero\n",
    "- **Use case:** Feature selection (automatic feature elimination)\n",
    "- **Formula:** `Œª √ó Œ£|Œ≤·µ¢|`\n",
    "\n",
    "#### üÖª2Ô∏è‚É£ L2 Regularization (Ridge)\n",
    "- Penalty = sum of squared coefficients\n",
    "- **Effect:** Shrinks all coefficients toward zero (but not to zero)\n",
    "- **Use case:** When all features matter, just reduce their impact\n",
    "- **Formula:** `Œª √ó Œ£Œ≤·µ¢¬≤`\n",
    "\n",
    "**Choosing Œª:**\n",
    "- Œª = 0: No regularization (may overfit)\n",
    "- Œª too small: Still overfits\n",
    "- Œª just right: Sweet spot! ‚ú®\n",
    "- Œª too large: Underfits (model too constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate overfitting vs regularization\n",
    "# Generate synthetic data with polynomial pattern\n",
    "np.random.seed(42)\n",
    "X_demo = np.sort(np.random.rand(50, 1) * 10, axis=0)\n",
    "y_demo = 2 * X_demo + 3 * np.sin(X_demo) + np.random.randn(50, 1) * 2\n",
    "\n",
    "# Create polynomial features (degree 15 - way too complex!)\n",
    "poly_15 = PolynomialFeatures(degree=15)\n",
    "X_demo_poly = poly_15.fit_transform(X_demo)\n",
    "\n",
    "# Train three models:\n",
    "# 1. Linear (underfitting)\n",
    "# 2. Polynomial without regularization (overfitting)\n",
    "# 3. Polynomial with regularization (good fit)\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_demo, y_demo)\n",
    "\n",
    "overfit_model = LinearRegression()\n",
    "overfit_model.fit(X_demo_poly, y_demo)\n",
    "\n",
    "regularized_model = Ridge(alpha=10.0)  # L2 regularization\n",
    "regularized_model.fit(X_demo_poly, y_demo)\n",
    "\n",
    "# Create smooth line for plotting\n",
    "X_plot = np.linspace(0, 10, 300).reshape(-1, 1)\n",
    "X_plot_poly = poly_15.transform(X_plot)\n",
    "\n",
    "# Predictions\n",
    "y_linear = linear_model.predict(X_plot)\n",
    "y_overfit = overfit_model.predict(X_plot_poly)\n",
    "y_regularized = regularized_model.predict(X_plot_poly)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Underfitting\n",
    "ax1.scatter(X_demo, y_demo, alpha=0.6, s=60, color='gray', edgecolors='white', linewidth=1.5, label='Data')\n",
    "ax1.plot(X_plot, y_linear, linewidth=3, color='#ef4444', label='Linear Model')\n",
    "ax1.set_title('Underfitting\\n(Too Simple - High Bias)', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('X', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('y', fontsize=11, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting\n",
    "ax2.scatter(X_demo, y_demo, alpha=0.6, s=60, color='gray', edgecolors='white', linewidth=1.5, label='Data')\n",
    "ax2.plot(X_plot, y_overfit, linewidth=3, color='#3b82f6', label='Degree-15 Polynomial')\n",
    "ax2.set_title('Overfitting\\n(Too Complex - High Variance)', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('X', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('y', fontsize=11, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(y_demo.min() - 10, y_demo.max() + 10)\n",
    "\n",
    "# Good fit (with regularization)\n",
    "ax3.scatter(X_demo, y_demo, alpha=0.6, s=60, color='gray', edgecolors='white', linewidth=1.5, label='Data')\n",
    "ax3.plot(X_plot, y_regularized, linewidth=3, color='#10b981', label='Regularized Polynomial')\n",
    "ax3.set_title('Good Fit with Regularization\\n(Balanced - Low Bias & Variance)', fontsize=13, fontweight='bold')\n",
    "ax3.set_xlabel('X', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('y', fontsize=11, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('The Bias-Variance Tradeoff', fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ What You're Seeing:\")\n",
    "print(\"   LEFT (Red): Too simple ‚Üí misses the pattern (underfitting)\")\n",
    "print(\"   MIDDLE (Blue): Too complex ‚Üí memorizes noise (overfitting)\")\n",
    "print(\"   RIGHT (Green): Just right ‚Üí captures pattern, ignores noise (regularization!)\")\n",
    "print(\"\\nüí° Regularization prevents the wild oscillations of overfitting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Ridge vs Lasso regularization\n",
    "# Use California housing data\n",
    "\n",
    "# Try different regularization strengths\n",
    "alphas = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "ridge_scores = []\n",
    "lasso_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Ridge (L2)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    ridge_scores.append(ridge.score(X_test_scaled, y_test))\n",
    "    \n",
    "    # Lasso (L1)\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    lasso_scores.append(lasso.score(X_test_scaled, y_test))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "ax.semilogx(alphas, ridge_scores, marker='o', linewidth=3, markersize=10, \n",
    "           label='Ridge (L2) Regularization', color='#3b82f6')\n",
    "ax.semilogx(alphas, lasso_scores, marker='s', linewidth=3, markersize=10, \n",
    "           label='Lasso (L1) Regularization', color='#f59e0b')\n",
    "\n",
    "ax.set_xlabel('Regularization Strength (Œ±)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('R¬≤ Score on Test Set', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Effect of Regularization Strength\\n(Higher Œ± = More Regularization)', \n",
    "            fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark optimal points\n",
    "best_ridge_idx = np.argmax(ridge_scores)\n",
    "best_lasso_idx = np.argmax(lasso_scores)\n",
    "\n",
    "ax.plot(alphas[best_ridge_idx], ridge_scores[best_ridge_idx], \n",
    "       marker='*', markersize=20, color='red', label='Optimal Ridge')\n",
    "ax.plot(alphas[best_lasso_idx], lasso_scores[best_lasso_idx], \n",
    "       marker='*', markersize=20, color='green', label='Optimal Lasso')\n",
    "\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Regularization Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Ridge Œ±: {alphas[best_ridge_idx]:.3f} ‚Üí R¬≤ = {ridge_scores[best_ridge_idx]:.4f}\")\n",
    "print(f\"Best Lasso Œ±: {alphas[best_lasso_idx]:.3f} ‚Üí R¬≤ = {lasso_scores[best_lasso_idx]:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"   ‚Üí Too little regularization (Œ± < 0.01): Similar to no regularization\")\n",
    "print(\"   ‚Üí Sweet spot (Œ± ~ 0.1-1.0): Best test performance\")\n",
    "print(\"   ‚Üí Too much regularization (Œ± > 10): Underfitting, poor performance\")\n",
    "print(\"   ‚Üí Ridge generally more stable than Lasso for this dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Exercise 1: Build and Compare Regressors\n",
    "\n",
    "**Objective:** Practice building regression models and understanding regularization\n",
    "\n",
    "**Task:**  \n",
    "Using the California housing dataset:\n",
    "1. Train THREE models: LinearRegression, Ridge(alpha=1.0), Lasso(alpha=1.0)\n",
    "2. Compare their R¬≤ scores on the test set\n",
    "3. Examine feature coefficients for each model\n",
    "4. Which model performs best? Why?\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint: Getting Started</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# Train models\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=1.0)\n",
    "\n",
    "# Fit on training data\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "# ... (do same for ridge and lasso)\n",
    "\n",
    "# Evaluate on test data\n",
    "print(f\"Linear Regression R¬≤: {lr.score(X_test_scaled, y_test):.4f}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Exercise 2: Classification Threshold Tuning\n",
    "\n",
    "**Objective:** Understand how classification thresholds affect precision and recall\n",
    "\n",
    "**Context:**  \n",
    "By default, logistic regression uses 0.5 as the decision threshold:\n",
    "- P(disease) > 0.5 ‚Üí Predict disease\n",
    "- P(disease) ‚â§ 0.5 ‚Üí Predict no disease\n",
    "\n",
    "**Task:**  \n",
    "1. Try different thresholds: 0.3, 0.5, 0.7\n",
    "2. For each threshold, calculate precision and recall\n",
    "3. Observe the tradeoff: lowering threshold increases recall but decreases precision\n",
    "\n",
    "**Questions:**\n",
    "- Which threshold would you choose for disease screening (where missing cases is dangerous)?\n",
    "- Which threshold for spam detection (where false alarms are annoying)?\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint: How to Apply Threshold</summary>\n",
    "\n",
    "```python\n",
    "# Get probabilities\n",
    "probs = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Apply custom threshold\n",
    "threshold = 0.3\n",
    "predictions = (probs > threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "Let's recap what we've mastered in supervised learning:\n",
    "\n",
    "- ‚úÖ **Supervised learning fundamentals**: Learn from labeled input-output pairs\n",
    "- ‚úÖ **Regression**: Predict continuous values (prices, quantities, measurements)\n",
    "  - Metrics: R¬≤, RMSE, MAE\n",
    "  - Algorithms: Linear Regression, Ridge, Lasso\n",
    "- ‚úÖ **Classification**: Predict discrete categories (spam/not, disease/healthy)\n",
    "  - Metrics: Accuracy, Precision, Recall, F1, ROC-AUC\n",
    "  - Algorithms: Logistic Regression (and more in 2.2!)\n",
    "- ‚úÖ **Overfitting**: The #1 ML challenge‚Äîmemorizing instead of learning\n",
    "- ‚úÖ **Regularization**: L1 (Lasso) and L2 (Ridge) prevent overfitting\n",
    "- ‚úÖ **Metric selection**: Choose metrics based on business cost of errors\n",
    "\n",
    "### ü§î The Big Picture:\n",
    "\n",
    "**70% of real-world ML is supervised learning** because:\n",
    "1. You have clear targets (labeled data)\n",
    "2. Success is measurable (test set performance)\n",
    "3. It works reliably when you have enough data\n",
    "4. It's interpretable (you can explain predictions)\n",
    "\n",
    "**The workflow:**\n",
    "1. Define problem (regression or classification?)\n",
    "2. Collect & label data\n",
    "3. Split: train-validation-test\n",
    "4. Train models, tune hyperparameters\n",
    "5. Evaluate honestly on test set\n",
    "6. Deploy and monitor!\n",
    "\n",
    "You now have the foundation to solve 70% of ML problems! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Further Learning\n",
    "\n",
    "**Recommended Reading:**\n",
    "- [scikit-learn Supervised Learning Guide](https://scikit-learn.org/stable/supervised_learning.html) - Official comprehensive reference\n",
    "- [Andrew Ng's ML Course](https://www.coursera.org/learn/machine-learning) - The gold standard (free)\n",
    "- [Google's ML Crash Course](https://developers.google.com/machine-learning/crash-course) - Interactive and practical\n",
    "\n",
    "**Deep Dives:**\n",
    "- [StatQuest: Regularization](https://www.youtube.com/watch?v=Q81RR3yKn30) - Visual explanations\n",
    "- [Understanding ROC Curves](https://www.youtube.com/watch?v=4jRBRDbJemM) - Essential for classification\n",
    "- [Bias-Variance Tradeoff](https://www.youtube.com/watch?v=EuBBz3bI-aA) - Core ML concept\n",
    "\n",
    "**Interactive Practice:**\n",
    "- [Kaggle Learn: Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) - Hands-on exercises\n",
    "- [Google Colab Tutorials](https://colab.research.google.com/notebooks/intro.ipynb) - Free GPU notebooks\n",
    "\n",
    "**Research Papers** (for the curious):\n",
    "- [An Introduction to Statistical Learning](https://www.statlearning.com/) - Free textbook, highly accessible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚û°Ô∏è What's Next?\n",
    "\n",
    "You've mastered the fundamentals of supervised learning! Next up:\n",
    "\n",
    "**In Chapter 2.2 - Classification vs Regression**, you'll learn:\n",
    "\n",
    "**Coming up:**\n",
    "- **When to use which**: Decision framework for choosing regression vs classification\n",
    "- **Advanced regression**: Polynomial regression, feature engineering tricks\n",
    "- **Advanced classification**: Multi-class, multi-label, and imbalanced datasets\n",
    "- **Model selection**: How to choose the right algorithm for your problem\n",
    "- **Real-world case studies**: End-to-end projects with messy data\n",
    "\n",
    "You'll go from understanding concepts to making confident modeling decisions! üéØ\n",
    "\n",
    "Ready to dive deeper? Open **[Chapter 2.2 - Classification vs Regression](2.2-classification-vs-regression.ipynb)**!\n",
    "\n",
    "---\n",
    "\n",
    "### üí¨ Feedback & Community\n",
    "\n",
    "**Questions?** Join our [Discord community](https://discord.gg/madeforai)\n",
    "\n",
    "**Found a bug?** [Open an issue on GitHub](https://github.com/madeforai/madeforai/issues)\n",
    "\n",
    "**Share your projects!** Tweet with #MadeForAI\n",
    "\n",
    "**Keep learning!** üåü"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
