{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - Introduction to AI, ML, and Deep Learning\n",
    "\n",
    "Welcome to your first step in the AI journey! In this chapter, we'll explore the foundations of Artificial Intelligence, Machine Learning, and Deep Learning. You'll understand how these concepts relate to each other and build your first simple ML model.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- What is Artificial Intelligence?\n",
    "- The relationship between AI, ML, and DL\n",
    "- Key ML paradigms (Supervised, Unsupervised, Reinforcement)\n",
    "- Build a simple linear regression model\n",
    "- The GenAI landscape in 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install and import the libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running in Colab)\n",
    "# !pip install numpy matplotlib scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. What is Artificial Intelligence?\n",
    "\n",
    "**Artificial Intelligence (AI)** is the field of computer science focused on creating systems that can perform tasks that typically require human intelligence.\n",
    "\n",
    "### The AI Hierarchy\n",
    "\n",
    "Think of AI as a set of nested concepts:\n",
    "\n",
    "```\n",
    "\n",
    "   Artificial Intelligence (AI)       \u2190 Broad field: Any intelligent behavior\n",
    "    \n",
    "     Machine Learning (ML)           \u2190 Learning from data\n",
    "        \n",
    "       Deep Learning (DL)          \u2190 Neural networks with many layers\n",
    "            \n",
    "        GenAI / LLMs             \u2190 Generative models (GPT, Claude, etc.)\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "**Key Insight:** All Deep Learning is Machine Learning, all Machine Learning is AI, but not all AI is Machine Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Paradigms\n",
    "\n",
    "Machine Learning can be categorized into three main paradigms based on how the model learns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the ML paradigms\n",
    "paradigms = {\n",
    "    ' Supervised Learning': {\n",
    "        'description': 'Learning from labeled data (input \u2192 output pairs)',\n",
    "        'examples': ['Classification', 'Regression'],\n",
    "        'use_cases': ['Spam detection', 'House price prediction', 'Image recognition']\n",
    "    },\n",
    "    ' Unsupervised Learning': {\n",
    "        'description': 'Finding patterns in unlabeled data',\n",
    "        'examples': ['Clustering', 'Dimensionality Reduction'],\n",
    "        'use_cases': ['Customer segmentation', 'Anomaly detection', 'Data compression']\n",
    "    },\n",
    "    ' Reinforcement Learning': {\n",
    "        'description': 'Learning through trial and error with rewards',\n",
    "        'examples': ['Q-Learning', 'Policy Gradients'],\n",
    "        'use_cases': ['Game playing (AlphaGo)', 'Robotics', 'Self-driving cars']\n",
    "    }\n",
    "}\n",
    "\n",
    "for paradigm, info in paradigms.items():\n",
    "    print(f\"\\n{paradigm}\")\n",
    "    print(f\"   {info['description']}\")\n",
    "    print(f\"   Examples: {', '.join(info['examples'])}\")\n",
    "    print(f\"   Use Cases: {', '.join(info['use_cases'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Your First ML Model: Linear Regression\n",
    "\n",
    "Let's build a simple **supervised learning** model to predict house prices based on size. This is a classic regression problem.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Given the size of a house (in square feet), can we predict its price?\n",
    "\n",
    "We'll use the formula: **Price = m \u00d7 Size + b**\n",
    "\n",
    "Where:\n",
    "- **m** = slope (how much price increases per square foot)\n",
    "- **b** = intercept (base price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic house data\n",
    "np.random.seed(42)\n",
    "\n",
    "# House sizes (square feet)\n",
    "sizes = np.random.randint(500, 3500, 100).reshape(-1, 1)\n",
    "\n",
    "# Prices (with some realistic noise)\n",
    "# True relationship: Price = 150 * Size + 50000 + noise\n",
    "prices = 150 * sizes + 50000 + np.random.randn(100, 1) * 20000\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sizes, prices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(f\"Size: {X_train[0][0]:.0f} sq ft \u2192 Price: ${y_train[0][0]:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(X_train, y_train, alpha=0.6, c='#3b82f6', \n",
    "           edgecolors='white', s=80, label='Training Data')\n",
    "plt.scatter(X_test, y_test, alpha=0.6, c='#f59e0b', \n",
    "           edgecolors='white', s=80, label='Test Data')\n",
    "\n",
    "plt.xlabel('House Size (sq ft)', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Price ($)', fontsize=13, fontweight='bold')\n",
    "plt.title('House Prices vs Size', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\" Our goal: Find the best line that fits this data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Now let's train a linear regression model to learn the relationship between size and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the learned parameters\n",
    "slope = model.coef_[0][0]\n",
    "intercept = model.intercept_[0]\n",
    "\n",
    "print(\" Model Training Complete!\\n\")\n",
    "print(f\"Learned equation: Price = {slope:.2f} \u00d7 Size + {intercept:,.0f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  \u2022 Base price: ${intercept:,.0f}\")\n",
    "print(f\"  \u2022 Price per sq ft: ${slope:.2f}\")\n",
    "print(f\"\\n This means each additional square foot adds ${slope:.2f} to the price!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model Performance (R\u00b2 Score):\")\n",
    "print(f\"  Training: {train_score:.4f}\")\n",
    "print(f\"  Testing:  {test_score:.4f}\")\n",
    "print(f\"\\n A score close to 1.0 means excellent predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X_train, y_train, alpha=0.6, c='#3b82f6', \n",
    "           edgecolors='white', s=80, label='Training Data')\n",
    "plt.scatter(X_test, y_test, alpha=0.6, c='#f59e0b', \n",
    "           edgecolors='white', s=80, label='Test Data')\n",
    "\n",
    "# Plot the learned line\n",
    "X_line = np.linspace(sizes.min(), sizes.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(X_line)\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=3, label='Learned Model', alpha=0.8)\n",
    "\n",
    "plt.xlabel('House Size (sq ft)', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Price ($)', fontsize=13, fontweight='bold')\n",
    "plt.title('Linear Regression: Predictions vs Actual', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "Now let's use our trained model to predict prices for new houses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict prices for new houses\n",
    "new_houses = np.array([[1000], [1500], [2000], [2500], [3000]])\n",
    "predicted_prices = model.predict(new_houses)\n",
    "\n",
    "print(\" Price Predictions for New Houses:\\n\")\n",
    "print(\"Size (sq ft)  \u2192  Predicted Price\")\n",
    "print(\"\" * 40)\n",
    "for size, price in zip(new_houses, predicted_prices):\n",
    "    print(f\"{size[0]:>6,} sq ft  \u2192  ${price[0]:>12,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. From ML to Deep Learning\n",
    "\n",
    "Linear regression is simple, but what if the relationship isn't linear? That's where **Deep Learning** comes in!\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Aspect | Traditional ML | Deep Learning |\n",
    "|--------|---------------|---------------|\n",
    "| **Model** | Simple (linear, trees) | Neural networks with many layers |\n",
    "| **Features** | Manual engineering | Automatic learning |\n",
    "| **Data Needed** | Works with small data | Needs large datasets |\n",
    "| **Complexity** | Simple patterns | Complex patterns |\n",
    "| **Examples** | Linear regression, SVM | CNNs, Transformers, LLMs |\n",
    "\n",
    "### Neural Network Visualization\n",
    "\n",
    "```\n",
    "Input Layer    Hidden Layers    Output Layer\n",
    "                                    \n",
    "               \n",
    "                                          \n",
    "                       \n",
    "```\n",
    "\n",
    "Each connection has a **weight** that the network learns during training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The GenAI Landscape (2026)\n",
    "\n",
    "Today's Generative AI ecosystem is built on deep learning, specifically **Transformer** architectures.\n",
    "\n",
    "### Popular Models\n",
    "\n",
    "| Category | Examples | Key Features |\n",
    "|----------|----------|-------------|\n",
    "| **Large Language Models** | GPT-4, Claude, Gemini | Text generation, reasoning, coding |\n",
    "| **Small Language Models** | Phi-3, Gemma, Qwen | Efficient, edge-deployable |\n",
    "| **Multimodal Models** | GPT-4V, Gemini Pro | Vision + Language |\n",
    "| **Code Models** | Codex, StarCoder, CodeLlama | Specialized for programming |\n",
    "| **Open Source** | Llama 3, Mistral, Mixtral | Community-driven, customizable |\n",
    "\n",
    "### How LLMs Work (Simplified)\n",
    "\n",
    "1. **Training**: Learn patterns from billions of text examples\n",
    "2. **Tokenization**: Break text into pieces (tokens)\n",
    "3. **Prediction**: Predict the next token based on context\n",
    "4. **Generation**: Repeat to generate full responses\n",
    "\n",
    "We'll dive deeper into these concepts in later modules!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Key Takeaways\n",
    "\n",
    "1. **AI** is the broad field; **ML** learns from data; **DL** uses neural networks\n",
    "2. **Supervised learning** uses labeled data (like our house price example)\n",
    "3. The core ML loop: **Data \u2192 Model \u2192 Training \u2192 Predictions**\n",
    "4. **Deep Learning** adds layers and complexity for harder problems\n",
    "5. **LLMs** are the frontier of GenAI, built on transformer architectures\n",
    "\n",
    "##  Next Steps\n",
    "\n",
    "Continue to [Chapter 2: Your First Neural Network](chapter-2-first-neural-network.ipynb) to build a real neural network from scratch!\n",
    "\n",
    "---\n",
    "\n",
    "##  Practice Exercise\n",
    "\n",
    "Try modifying the code above to:\n",
    "1. Change the relationship between size and price\n",
    "2. Add more features (e.g., number of bedrooms)\n",
    "3. Experiment with different train/test splits\n",
    "\n",
    "---\n",
    "\n",
    "*\u00a9 2026 MadeForAI. Learn more at [madeforai.github.io](https://madeforai.github.io/madeforai)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}