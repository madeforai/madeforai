{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - What is Artificial Intelligence?\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/madeforai/madeforai/blob/main/docs/understanding-ai/module-1/1.1-what-is-ai.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Your first step into the fascinating world of AI‚Äîwhere machines learn, adapt, and solve problems like never before.**\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "- **What AI really means** and how it differs from traditional programming\n",
    "- **The history and evolution** of AI from the 1950s to today\n",
    "- **Key types of AI** and how they're used in everyday applications\n",
    "- **Build your first AI classifier** to classify whether text is positive or negative\n",
    "\n",
    "## ‚è±Ô∏è Estimated Time\n",
    "25-30 minutes\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Basic Python knowledge (variables, functions, lists)\n",
    "- Curiosity and enthusiasm! ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Welcome to the AI Revolution\n",
    "\n",
    "Imagine teaching a computer to recognize your handwriting, recommend movies you'll love, or even have a conversation with you. Sound like science fiction? Welcome to 2026‚Äîwhere Artificial Intelligence is not just real, it's everywhere!\n",
    "\n",
    "But what exactly *is* AI? At its core, **Artificial Intelligence** is the science of making computers do things that would normally require human intelligence‚Äîlike seeing, hearing, learning, reasoning, and making decisions.\n",
    "\n",
    "Here's the key difference: \n",
    "- **Traditional programming**: You write exact rules ‚Üí Computer follows them\n",
    "- **AI programming**: You give examples ‚Üí Computer learns the rules\n",
    "\n",
    "Think of it like teaching a child to ride a bike. You don't write a manual with every muscle movement. Instead, you show them, let them practice, and they *learn* through experience. That's AI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ A Brief History: From Dreams to Reality\n",
    "\n",
    "Let's take a quick journey through time to see how we got here:\n",
    "\n",
    "**1950s - The Birth** üçº  \n",
    "Alan Turing asked \"Can machines think?\" The Turing Test was born. First AI programs played checkers.\n",
    "\n",
    "**1960s-70s - Early Optimism** üåÖ  \n",
    "Researchers believed human-level AI was just around the corner. ELIZA chatbot fooled people into thinking it understood them.\n",
    "\n",
    "**1980s-90s - AI Winter** ‚ùÑÔ∏è  \n",
    "Progress slowed, funding dried up. Too much hype, not enough computing power.\n",
    "\n",
    "**2000s - The Comeback** üî•  \n",
    "Big data + faster computers + better algorithms = AI Renaissance. Google, Facebook, Amazon invest heavily.\n",
    "\n",
    "**2010s - Deep Learning Era** üöÄ  \n",
    "Neural networks conquer image recognition, speech recognition, game playing (AlphaGo beats world champion).\n",
    "\n",
    "**2020s - AI Everywhere** üåç  \n",
    "ChatGPT, DALL-E, self-driving cars, protein folding (AlphaFold), and you're learning AI right now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Types of AI: Understanding the Landscape\n",
    "\n",
    "AI isn't one thing‚Äîit's a spectrum of capabilities:\n",
    "\n",
    "### By Intelligence Level:\n",
    "\n",
    "1. **Narrow AI (ANI)** - Specialized in ONE task\n",
    "   - Your Spotify recommendations\n",
    "   - Face unlock on your phone  \n",
    "   - Gmail's spam filter\n",
    "   - *Status: Everywhere today! This is what we'll learn to build.*\n",
    "\n",
    "2. **General AI (AGI)** - Human-like intelligence across ANY task  \n",
    "   - Can learn any intellectual task a human can\n",
    "   - Understands context and transfers knowledge\n",
    "   - *Status: Doesn't exist yet (researchers debate when/if it will)*\n",
    "\n",
    "3. **Super AI (ASI)** - Surpasses human intelligence\n",
    "   - Exceeds humans in creativity, problem-solving, everything\n",
    "   - *Status: Pure speculation (might never happen)*\n",
    "\n",
    "### By Learning Approach:\n",
    "\n",
    "1. **Machine Learning (ML)** - Learns patterns from data\n",
    "2. **Deep Learning (DL)** - ML using neural networks (many layers)\n",
    "3. **Reinforcement Learning (RL)** - Learns through trial and error (like training a dog)\n",
    "\n",
    "Don't worry if this feels like a lot‚Äîwe'll explore each in detail throughout this course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Install required packages\n",
    "# Uncomment the line below if running in Google Colab\n",
    "# !pip install numpy matplotlib pandas scikit-learn seaborn -q\n",
    "\n",
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Set visualization style for beautiful plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Setup complete! All libraries loaded successfully.\")\n",
    "print(\"üéØ Ready to build your first AI model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Your First AI Model: Sentiment Classifier\n",
    "\n",
    "Theory is great, but let's get our hands dirty! We're going to build a simple AI that can tell whether a movie review is **positive** or **negative**. This is called **sentiment analysis**, and companies use it to:\n",
    "- Analyze customer feedback\n",
    "- Monitor brand reputation on social media\n",
    "- Understand public opinion\n",
    "\n",
    "### The Game Plan:\n",
    "\n",
    "1. **Collect data** - Get example reviews (labeled as positive/negative)\n",
    "2. **Prepare data** - Convert text to numbers (computers love numbers!)\n",
    "3. **Train model** - Let the AI learn patterns from examples\n",
    "4. **Test model** - See how well it predicts on new reviews\n",
    "5. **Use model** - Classify new, unseen reviews\n",
    "\n",
    "Let's do this! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create our training data\n",
    "# In real projects, you'd have thousands of reviews. We'll start small to understand the concept.\n",
    "\n",
    "# Positive reviews (label = 1)\n",
    "positive_reviews = [\n",
    "    \"This movie was fantastic! I loved every minute.\",\n",
    "    \"Absolutely brilliant performance. A must-watch!\",\n",
    "    \"Best film I've seen this year. Highly recommend.\",\n",
    "    \"Amazing storyline and great acting. Superb!\",\n",
    "    \"I enjoyed this movie thoroughly. Well done!\",\n",
    "    \"Outstanding cinematography and direction.\",\n",
    "    \"This exceeded all my expectations. Wonderful!\",\n",
    "    \"A masterpiece of modern cinema. Loved it!\"\n",
    "]\n",
    "\n",
    "# Negative reviews (label = 0)\n",
    "negative_reviews = [\n",
    "    \"Terrible movie. Complete waste of time.\",\n",
    "    \"I hated every second. Absolutely awful.\",\n",
    "    \"Boring and predictable. Very disappointing.\",\n",
    "    \"Poor acting and weak plot. Not worth watching.\",\n",
    "    \"This was bad. I want my money back.\",\n",
    "    \"Worst movie I've seen. Total disaster.\",\n",
    "    \"Dreadful film with horrible dialogue.\",\n",
    "    \"Painfully boring. I almost fell asleep.\"\n",
    "]\n",
    "\n",
    "# Combine and create labels\n",
    "reviews = positive_reviews + negative_reviews\n",
    "labels = [1] * len(positive_reviews) + [0] * len(negative_reviews)\n",
    "\n",
    "print(f\"üìä Dataset created with {len(reviews)} reviews:\")\n",
    "print(f\"   - Positive reviews: {len(positive_reviews)}\")\n",
    "print(f\"   - Negative reviews: {len(negative_reviews)}\")\n",
    "print(\"\\nüîç Sample positive review:\", positive_reviews[0])\n",
    "print(\"üîç Sample negative review:\", negative_reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Converting Text to Numbers\n",
    "\n",
    "Computers can't read words the way we do‚Äîthey need numbers. We'll use a technique called **Bag of Words**:\n",
    "\n",
    "1. Look at all words across all reviews\n",
    "2. Create a \"vocabulary\" of unique words  \n",
    "3. For each review, count how many times each word appears\n",
    "4. Create a vector of numbers representing that review\n",
    "\n",
    "**Example:**  \n",
    "Vocabulary: `[\"movie\", \"good\", \"bad\", \"love\", \"hate\"]`  \n",
    "Review: *\"I love this movie\"*  \n",
    "Vector: `[1, 0, 0, 1, 0]` (1 \"movie\", 1 \"love\", rest are 0)\n",
    "\n",
    "<!-- [PLACEHOLDER IMAGE]\n",
    "Prompt for image generation:\n",
    "\"Create an educational diagram showing text-to-numbers conversion using Bag of Words.\n",
    "Style: Clean, minimalist, infographic style.\n",
    "Elements: \n",
    "- Left side: 3 sample text reviews (shown as documents)\n",
    "- Middle: Vocabulary list (showing unique words extracted)\n",
    "- Right side: Numerical vectors (showing word counts as numbers in boxes)\n",
    "- Arrows connecting each element showing the transformation process\n",
    "Color scheme: Blue and orange gradient with white background.\n",
    "Include labels: 'Text Input', 'Vocabulary', 'Numerical Vectors'.\n",
    "Format: Wide horizontal layout (16:9 ratio).\" -->\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert text to numbers using CountVectorizer\n",
    "# This is our \"translator\" from words to numbers\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "# lowercase=True: Convert all text to lowercase (\"Good\" and \"good\" are the same)\n",
    "# stop_words='english': Remove common words like \"the\", \"is\", \"and\" (they don't help much)\n",
    "\n",
    "# Fit and transform: Learn vocabulary + convert reviews to numbers\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "print(\"üî§ Vocabulary learned:\")\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"   Total unique words: {len(vocab)}\")\n",
    "print(f\"   Sample words: {list(vocab[:15])}\")\n",
    "\n",
    "print(\"\\nüî¢ Review converted to numbers:\")\n",
    "print(f\"   Shape of our data: {X.shape}\")\n",
    "print(f\"   (This means {X.shape[0]} reviews, each represented by {X.shape[1]} numbers)\")\n",
    "\n",
    "# Let's see what one review looks like as numbers\n",
    "print(\"\\nüìù First review (original):\", reviews[0])\n",
    "print(\"üìä First review (as numbers):\")\n",
    "first_review_vector = X[0].toarray()[0]\n",
    "# Show only non-zero values for clarity\n",
    "non_zero_indices = np.where(first_review_vector > 0)[0]\n",
    "for idx in non_zero_indices:\n",
    "    print(f\"   '{vocab[idx]}': {first_review_vector[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Training Our AI Model\n",
    "\n",
    "Now comes the magic! We'll use a **Naive Bayes classifier**‚Äîa simple but effective algorithm that learns probability patterns.\n",
    "\n",
    "**How it works (simplified):**\n",
    "- Looks at which words appear more in positive vs negative reviews\n",
    "- Calculates probability: \"If this word appears, how likely is this review positive?\"\n",
    "- For a new review, combines probabilities of all its words to make a prediction\n",
    "\n",
    "**Fun fact:** Despite its name \"naive\", this algorithm powers spam filters in millions of email accounts! üìß\n",
    "\n",
    "<!-- [PLACEHOLDER IMAGE]\n",
    "Prompt for image generation:\n",
    "\"Create a simple diagram showing how a Naive Bayes classifier works for sentiment analysis.\n",
    "Style: Friendly, educational, colorful.\n",
    "Elements:\n",
    "- Top: Two groups of words (positive words in green, negative words in red)\n",
    "- Middle: A new review coming in (shown as a document icon with an arrow)\n",
    "- Bottom: The classifier analyzing word probabilities (shown as a simple flowchart)\n",
    "- Final prediction shown as thumbs up (positive) or thumbs down (negative)\n",
    "Include thought bubble from classifier saying 'Calculating probabilities...'\n",
    "Color scheme: Green for positive, red for negative, blue for the classifier.\n",
    "Format: Vertical layout.\" -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split data into training and testing sets\n",
    "# We'll use 80% to train, 20% to test how well the model learned\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"üìö Data split:\")\n",
    "print(f\"   Training samples: {len(y_train)}\")\n",
    "print(f\"   Testing samples: {len(y_test)}\")\n",
    "\n",
    "# Step 4: Create and train our AI model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nüéâ Model trained successfully!\")\n",
    "print(\"   The AI has learned patterns from the training reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Test how well our model performs\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"üìä Model Performance:\")\n",
    "print(f\"   Accuracy: {accuracy * 100:.1f}%\")\n",
    "print(f\"   ({int(accuracy * len(y_test))} out of {len(y_test)} predictions correct)\")\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'],\n",
    "            cbar=False)\n",
    "plt.title('Confusion Matrix: How Well Did Our AI Perform?', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Reading the matrix:\")\n",
    "print(\"   - Top-left: Correctly identified negative reviews\")\n",
    "print(\"   - Bottom-right: Correctly identified positive reviews\")\n",
    "print(\"   - Other squares: Mistakes (if any)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Using Our AI on New Reviews\n",
    "\n",
    "The moment of truth! Let's test our AI on reviews it has NEVER seen before. This is where the magic happens‚Äîcan it generalize its learning to new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New reviews the model has never seen\n",
    "new_reviews = [\n",
    "    \"This was an excellent movie with great performances!\",\n",
    "    \"Terrible waste of time. I hated it.\",\n",
    "    \"Mediocre at best. Expected much more.\",\n",
    "    \"Absolutely loved this film. A true gem!\",\n",
    "    \"Boring and slow. Not recommended.\"\n",
    "]\n",
    "\n",
    "# Convert new reviews to numbers (using the SAME vocabulary)\n",
    "X_new = vectorizer.transform(new_reviews)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new)\n",
    "probabilities = model.predict_proba(X_new)\n",
    "\n",
    "# Display results\n",
    "print(\"üîÆ AI Predictions on New Reviews:\\n\")\n",
    "for i, review in enumerate(new_reviews):\n",
    "    sentiment = \"üòä POSITIVE\" if predictions[i] == 1 else \"üòû NEGATIVE\"\n",
    "    confidence = max(probabilities[i]) * 100\n",
    "    \n",
    "    print(f\"Review {i+1}: \\\"{review}\\\"\")\n",
    "    print(f\"   Prediction: {sentiment}\")\n",
    "    print(f\"   Confidence: {confidence:.1f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Exercise 1: Experiment with Your Own Reviews\n",
    "\n",
    "**Objective:** Test the AI with your own movie reviews!\n",
    "\n",
    "**Task:**  \n",
    "1. Create 2-3 new movie reviews (can be positive or negative)\n",
    "2. Use the code below to see what the AI predicts\n",
    "3. Does it match your expectation? Why or why not?\n",
    "\n",
    "**Hints:**\n",
    "<details>\n",
    "<summary>üí° Hint 1: Creating reviews</summary>\n",
    "Think about what words the AI might have learned. Use clear positive/negative language.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint 2: Testing edge cases</summary>\n",
    "Try sarcastic reviews like \"Oh great, another terrible movie\" - will the AI understand sarcasm?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Add your own reviews here\n",
    "your_reviews = [\n",
    "    \"Add your first review here\",\n",
    "    \"Add your second review here\",\n",
    "    # Add more reviews if you want!\n",
    "]\n",
    "\n",
    "# Predict (same code as before)\n",
    "X_yours = vectorizer.transform(your_reviews)\n",
    "your_predictions = model.predict(X_yours)\n",
    "your_probs = model.predict_proba(X_yours)\n",
    "\n",
    "print(\"üéØ Your Reviews:\\n\")\n",
    "for i, review in enumerate(your_reviews):\n",
    "    sentiment = \"üòä POSITIVE\" if your_predictions[i] == 1 else \"üòû NEGATIVE\"\n",
    "    confidence = max(your_probs[i]) * 100\n",
    "    print(f\"Review: \\\"{review}\\\"\")\n",
    "    print(f\"   ‚Üí {sentiment} (Confidence: {confidence:.1f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Exercise 2: What Makes a Review Positive?\n",
    "\n",
    "**Objective:** Discover which words the AI associates with positive/negative reviews\n",
    "\n",
    "**Task:**  \n",
    "Look at the code below that shows the most \"important\" words for each sentiment. \n",
    "Do they make sense? Are there any surprises?\n",
    "\n",
    "**Expected Output:** Two lists of words‚Äîone for positive, one for negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "feature_log_prob = model.feature_log_prob_\n",
    "vocab_array = np.array(vocab)\n",
    "\n",
    "# Get top words for negative class (index 0)\n",
    "negative_indices = feature_log_prob[0].argsort()[-10:][::-1]\n",
    "negative_words = vocab_array[negative_indices]\n",
    "\n",
    "# Get top words for positive class (index 1)\n",
    "positive_indices = feature_log_prob[1].argsort()[-10:][::-1]\n",
    "positive_words = vocab_array[positive_indices]\n",
    "\n",
    "print(\"üî¥ Top words associated with NEGATIVE reviews:\")\n",
    "print(\"  \", list(negative_words))\n",
    "\n",
    "print(\"\\nüü¢ Top words associated with POSITIVE reviews:\")\n",
    "print(\"  \", list(positive_words))\n",
    "\n",
    "print(\"\\nüí≠ Think about it:\")\n",
    "print(\"   - Do these word lists make sense?\")\n",
    "print(\"   - Would you use similar words when writing reviews?\")\n",
    "print(\"   - What might the AI miss? (Hint: sarcasm, context, nuance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "Congratulations! You just built your first AI model. Let's recap what you learned:\n",
    "\n",
    "- ‚úÖ **AI vs Traditional Programming**: AI learns from examples, traditional code follows explicit rules\n",
    "- ‚úÖ **History Matters**: AI has evolved over 70+ years from theory to everyday applications\n",
    "- ‚úÖ **Types of AI**: Narrow AI (what we use today) vs General AI (the future goal)\n",
    "- ‚úÖ **Machine Learning Workflow**: Data ‚Üí Preparation ‚Üí Training ‚Üí Testing ‚Üí Deployment\n",
    "- ‚úÖ **Text to Numbers**: Computers need numerical representations to process text\n",
    "- ‚úÖ **Real AI in Action**: You built a sentiment classifier that actually works!\n",
    "\n",
    "### ü§î Limitations to Remember:\n",
    "- Our model can't understand sarcasm or context  \n",
    "- It needs much more data to be production-ready\n",
    "- Simple bag-of-words ignores word order\n",
    "\n",
    "But that's okay‚Äîwe're just getting started! üå±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Further Learning\n",
    "\n",
    "**Recommended Reading:**\n",
    "- [AI For Everyone by Andrew Ng (Coursera)](https://www.coursera.org/learn/ai-for-everyone) - Excellent non-technical overview\n",
    "- [A Brief History of AI](https://www.ibm.com/topics/artificial-intelligence) - IBM's comprehensive timeline\n",
    "- [What is Sentiment Analysis?](https://monkeylearn.com/sentiment-analysis/) - Deep dive into this application\n",
    "\n",
    "**Video Tutorials:**\n",
    "- [AI Explained by Google](https://www.youtube.com/watch?v=mJeNghZXtMo) - 5-minute overview\n",
    "- [The History of AI](https://www.youtube.com/watch?v=ejvlZ2jPb5o) - Animated timeline\n",
    "\n",
    "**Interactive Tools:**\n",
    "- [Google Teachable Machine](https://teachablemachine.withgoogle.com/) - Build AI models in your browser\n",
    "- [Quick, Draw!](https://quickdraw.withgoogle.com/) - See AI recognize your drawings in real-time\n",
    "\n",
    "**Research Papers** (for the curious):\n",
    "- [Computing Machinery and Intelligence](https://academic.oup.com/mind/article/LIX/236/433/986238) - Alan Turing's foundational paper (1950)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚û°Ô∏è What's Next?\n",
    "\n",
    "In the next chapter, **1.2 - The AI Landscape**, you'll learn about:\n",
    "\n",
    "**Coming up:**\n",
    "- The difference between Narrow, General, and Super AI in depth\n",
    "- Current AI applications across industries (healthcare, finance, entertainment)\n",
    "- The AI tech stack: ML, Deep Learning, NLP, Computer Vision, and more\n",
    "- Where we are in 2026 and where we're headed\n",
    "\n",
    "You've taken your first step into the AI world. The journey ahead is even more exciting! üöÄ\n",
    "\n",
    "Ready to continue? Open **[Chapter 1.2 - The AI Landscape](1.2-ai-landscape.ipynb)**!\n",
    "\n",
    "---\n",
    "\n",
    "### üí¨ Feedback\n",
    "Have questions or suggestions? We'd love to hear from you! Join our [Discord community](https://discord.gg/madeforai) or [open an issue on GitHub](https://github.com/madeforai/madeforai/issues).\n",
    "\n",
    "**Happy learning!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
